{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675d1711-8d44-435d-b82c-604d3f89b9e9",
   "metadata": {},
   "source": [
    "# Initial Work for Test Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdde970-c7a3-4fcf-853c-fc567b66fcb5",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb89a0-3de6-4ccd-be38-f0e118003d14",
   "metadata": {},
   "source": [
    "<div hidden>\n",
    "$\\usepackage{cancel}$\n",
    "$\\usepackage{amssymb}$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "632eb95f-72f6-4b11-84cd-33e48e92968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "#!pip install torch torchvision pandas numpy matplotlib scipy plotly tensorboard onyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb475e0-2bfc-4d6a-aa9d-20dbb7eb0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize tensorboard in the notebook\n",
    "%load_ext tensorboard\n",
    "# In order to force reload any changes done to the models package files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28295ed2-731a-4b1c-9573-9f19df5f96e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Bhavana\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models.simpleFork import Simple, Fork\n",
    "from models.danmf import DANMF\n",
    "from datasets.yt_vidframes import YtVidsDataset\n",
    "\n",
    "import os\n",
    "from collections import namedtuple\n",
    "from timeit import default_timer\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import onnx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd, diagsvd\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5cde01-0aeb-41f8-8ae3-9bf8c09959e0",
   "metadata": {},
   "source": [
    "### Per-run user defined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1961e23a-445b-4ba6-ada1-3366473f66c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the machine being used\n",
    "# machine = \"Macbook\"\n",
    "machine = \"PC\"\n",
    "\n",
    "## FORMAT: {machine}, {model}, {datetime}\n",
    "state_dict_str = \"{}_{}_state-dict_{}.pt\"\n",
    "state_dict_notime = \"{}_{}_state-dict\"\n",
    "checkpoint_dict_str = \"{}_{}_checkpoint_{}.tar\"\n",
    "checkpoint_dict_notime = \"{}_{}_checkpoint\"\n",
    "\n",
    "Checkpoint = namedtuple(\"Checkpoint\", [\"model\", \"epoch\", \"loss\", \"validation_loss\", \"opt_state_dict\", \"train_time\"])\n",
    "# data_dir = os.path.join(\"..\", \"data\")\n",
    "# output_dir = os.path.join(data_dir, \"output\")\n",
    "data_dir = os.path.join(\"..\", \"data\")\n",
    "output_dir = os.path.join(data_dir, \"output\")\n",
    "tensorboard_dir = os.path.join(output_dir, \"tensorboard\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf874b-645d-4c00-83cb-3295843464c8",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "We remove the channels in the images (convert to grayscale) to more closely mimic the actual plasma dataset\n",
    "\n",
    "* [Helpful Link](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "\n",
    "#### Normalization\n",
    "* Normalize each image with respect to its unit Frobenius norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d82384c-93c9-4e52-9158-c1ac31218743",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61ec189b-9ed7-4809-8cec-c7cc75b6b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset params\n",
    "batch_size = 25\n",
    "img_size = (54, 96)\n",
    "imgs_dir = os.path.join(data_dir, \"images_96x54\")\n",
    "\n",
    "# Load and split the data, and prep for being fed into the NN\n",
    "data = YtVidsDataset(imgs_dir)\n",
    "# Divide data into train, validation, test\n",
    "train_data, validation_data, test_data = random_split(data, [0.7, 0.2, 0.1])\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=(torch.cuda.is_available()), drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size, shuffle=True, pin_memory=(torch.cuda.is_available()), drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab1d863b-d541-4b73-aa75-ce19a38c8b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6741 <class 'torch.Tensor'> torch.Size([54, 96])\n",
      "tensor([[0.0160, 0.0155, 0.0152,  ..., 0.0163, 0.0162, 0.0162],\n",
      "        [0.0156, 0.0158, 0.0155,  ..., 0.0160, 0.0159, 0.0158],\n",
      "        [0.0148, 0.0154, 0.0150,  ..., 0.0158, 0.0157, 0.0156],\n",
      "        ...,\n",
      "        [0.0147, 0.0146, 0.0145,  ..., 0.0140, 0.0136, 0.0141],\n",
      "        [0.0147, 0.0146, 0.0145,  ..., 0.0140, 0.0136, 0.0141],\n",
      "        [0.0146, 0.0146, 0.0145,  ..., 0.0140, 0.0136, 0.0142]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[2669])\n",
    "print(len(data), type(data[0]), data[244].shape)\n",
    "print(data[2000])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8fd5925-3dde-43fb-bb48-cb34a28179f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "\n",
    "### Structure\n",
    "\n",
    "#### DANMF Implementation from papers\n",
    "\n",
    "* **Non-alternating/nonnegative Matrix Factorization (NMF)**: Classical deep NMF for a non-negative matrix X ∈ Rm×n + can be described as follows: first, X is decomposed as X ≈ U0V 0 where U 0 ∈ Rm×r0 +  and V 0 ∈ Rr0×n + . The coding matrix V 0 is then further decomposed as V 0 ≈ U 1V 1 where U 1 ∈ Rr0×r1 +  and V 1 ∈ Rr1×n +. The procedure is repeated until a pre-fixed number of layers is reached. [[2]](#r2)\n",
    "* **deep alternating non-negative matrix factorisation (DA-NMF)**: we propose to factorise the basis and coding matrices in an alternating order along the layers. [[2]](#r2)\n",
    "    * Uses approx 6-8 layers\n",
    "\n",
    "<img src=\"images/r2_fig1.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<!-- ![image.png](images/r2_fig1.png) -->\n",
    "\n",
    "\n",
    "### L-System\n",
    "* Using L (Lindenmayer) Systems to define strucure?\n",
    "* Node types:\n",
    "    * Terminating (1 -> 0)\n",
    "    * Splitting (1 -> 2)\n",
    "    * Unifying (2 ->1)\n",
    "    * Direct (1 -> 1)\n",
    "    * Starting (0 -> 1)\n",
    "\n",
    "\n",
    "### Loss Function\n",
    "We use methods defined in [[1]](#r1) to define our loss function <!-- $\\mathcal{L}$ \\\\ -->\n",
    "\n",
    "$$\n",
    "\\min_{\\substack{U \\in \\real^{m\\times r} \\\\ V \\in \\real^{r\\times n}}} ||X - ReLU(UV)||^2_F ,\n",
    "$$\n",
    "Where we are finding the square Frobenius norm of the difference between the original matrix $X$ and the rectified linear low rank representation matrices $UV$\n",
    "\n",
    "#### From paper\n",
    "\n",
    "Eq. 10-11 [[2]](#r2)\n",
    "\n",
    "\n",
    "\n",
    "### Optimizer\n",
    "\n",
    "Adam works fine / is standard\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e88ef72-8831-4488-9a7a-4211d0c43296",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efebd7fd-b883-464c-82ae-e10f5ef35163",
   "metadata": {},
   "source": [
    "### General params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93616b48-16f1-4a4e-ac2f-a7c671d6dc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Select device to use for compute power\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    # else \"mps\"\n",
    "    # if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "use_cuda = device == \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9e9a56-ae04-4ebd-b8f4-7807741360b9",
   "metadata": {},
   "source": [
    "### Various Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8348b213-00cf-4b74-9618-6258f0294c2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fork(\n",
      "  (input): Flatten(start_dim=1, end_dim=-1)\n",
      "  (seq): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=5184, out_features=500, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=500, out_features=400, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=400, out_features=300, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=300, out_features=200, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (U): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=200, out_features=300, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=300, out_features=200, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=324, bias=True)\n",
      "      (1): Unflatten(dim=1, unflattened_size=(54, 6))\n",
      "    )\n",
      "  )\n",
      "  (V): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=200, out_features=300, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=300, out_features=200, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=100, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=100, out_features=576, bias=True)\n",
      "      (1): Unflatten(dim=1, unflattened_size=(6, 96))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Fork {'stem_layer_dims': tensor([500., 400., 300., 200.]), 'fork_layer_dims': tensor([300., 200., 100., 100.]), 'rank': 6, 'img_size': tensor([54., 96.]), 'desc': 'Linear layers that fork into two separate channels for U, V'}\n"
     ]
    }
   ],
   "source": [
    "# layer_dims = (500, 400, 300, 200, 100, 100)\n",
    "\n",
    "model_fork = Fork().to(device)\n",
    "print(model_fork)\n",
    "print(model_fork.get_name(), model_fork.get_hyperparameters())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea7aec16-784a-46dd-80c7-3a228f055f8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANMF(\n",
      "  (input): Flatten(start_dim=1, end_dim=-1)\n",
      "  (U): ModuleDict(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=5184, out_features=8100, bias=True)\n",
      "      (1): Unflatten(dim=1, unflattened_size=(54, 150))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=15000, out_features=10500, bias=True)\n",
      "      (1): Unflatten(dim=1, unflattened_size=(150, 70))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=3500, out_features=2100, bias=True)\n",
      "      (1): Unflatten(dim=1, unflattened_size=(70, 30))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=1500, out_features=300, bias=True)\n",
      "      (1): Unflatten(dim=1, unflattened_size=(30, 10))\n",
      "    )\n",
      "  )\n",
      "  (V): ModuleDict(\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=14400, out_features=9600, bias=True)\n",
      "      (1): Unflatten(dim=1, unflattened_size=(100, 96))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=7000, out_features=5000, bias=True)\n",
      "      (1): Unflatten(dim=1, unflattened_size=(50, 100))\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=1500, out_features=500, bias=True)\n",
      "      (1): Unflatten(dim=1, unflattened_size=(10, 50))\n",
      "    )\n",
      "  )\n",
      "  (seq): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=5184, out_features=14400, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=14400, out_features=15000, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=15000, out_features=7000, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=7000, out_features=3500, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=3500, out_features=1500, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_danmf = DANMF().to(device)\n",
    "print(model_danmf)\n",
    "\n",
    "# writer = SummaryWriter(os.path.join(tensorboard_dir, f'{machine}_{model_danmf.get_name()}_{runname}'))\n",
    "# writer.add_graph(model_danmf, next(iter(train_dataloader)).to(device))\n",
    "# writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b75a6-8944-4e88-b88e-0bf3add65efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47453944-254c-480c-8f73-e7653132b7cc",
   "metadata": {},
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731c8b9-2373-4ed4-92c7-102b9155912c",
   "metadata": {},
   "source": [
    "### Save/Load checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5809c5ae-84ee-43af-aac5-725596decbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(mname, machine, output_run_dir, checkpoint_str=checkpoint_dict_notime, statedict_str=state_dict_notime):\n",
    "    checkpoint_dict, statedict = (None, None)\n",
    "    \n",
    "    if checkpoint_str:\n",
    "        name_checkpoint = checkpoint_dict_notime.format(machine, mname)\n",
    "        file_checkpoint = next((x for x in sorted(os.listdir(output_run_dir), reverse=True) if x.startswith(name_checkpoint)), None)\n",
    "        if file_checkpoint:\n",
    "            print(f\"Found checkpoint to load. Using: {file_checkpoint}\")\n",
    "            checkpoint_dict = torch.load(os.path.join(output_run_dir, file_checkpoint))\n",
    "\n",
    "    if statedict_str:  \n",
    "        name_statedict = state_dict_notime.format(machine, mname)\n",
    "        file_statedict = next((x for x in sorted(os.listdir(output_run_dir), reverse=True) if x.startswith(name_statedict)), None)\n",
    "        if file_statedict:\n",
    "            print(f\"Found model state dict to load. Using: {file_statedict}\")\n",
    "            statedict = torch.load(os.path.join(output_run_dir, file_statedict))\n",
    "            \n",
    "    return checkpoint_dict, statedict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cefc746-fea1-4a25-8d25-dfa204df7cfe",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34bde206-f104-482e-9ebc-deffcb50af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fcn(X, U, V):\n",
    "    return torch.mean(\n",
    "            torch.square(\n",
    "                torch.linalg.matrix_norm(X - nn.functional.relu(torch.bmm(U, V)),\n",
    "                # Don't enforce non-negativity on UV?\n",
    "                # torch.linalg.matrix_norm(X - torch.bmm(U, V), \n",
    "                                         ord='fro')))\n",
    "\n",
    "# loop over the dataset multiple times\n",
    "def train_model(model, optimizer, output_run_dir, epochs=15, checkpoint_at = 3, load = True, batch_pr = 200, writer=None, profiler=None, **kwargs):\n",
    "    mname = model.get_name()\n",
    "    start_epoch = -1\n",
    "\n",
    "    print(f\"Training {mname}\")\n",
    "    \n",
    "    # Attempt to load the previous checkpoint\n",
    "    if load:\n",
    "        checkpoint, statedict = load_checkpoint(mname, machine, output_run_dir)\n",
    "        if checkpoint and statedict:\n",
    "            start_epoch = checkpoint[\"epoch\"]\n",
    "            optimizer.load_state_dict(checkpoint[\"opt_state_dict\"])\n",
    "            model.load_state_dict(statedict)\n",
    "        else:\n",
    "            print(\"No checkpoint found to load. Using base model\")\n",
    "            \n",
    "\n",
    "    # Save basic hyperparams\n",
    "    if writer:\n",
    "        writer.add_hparams(model.get_hyperparameters(), {})\n",
    "        writer.flush()\n",
    "\n",
    "    loss_arr = []\n",
    "    validation_arr = []\n",
    "    time_arr = []\n",
    "    for e in range(start_epoch+1, start_epoch+1 + epochs ):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_time = 0.0\n",
    "        \n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            data = data.to(device)\n",
    "\n",
    "            # Write out a view of the NN graph, just once\n",
    "            if writer and e == 0 and i == 0:\n",
    "                writer.add_graph(model, data)\n",
    "                writer.flush()\n",
    "                torch.onnx.export(model, data, os.path.join(output_run_dir, f'{mname}_model.onnx'), input_names=[\"matrix\"], output_names=[\"V\", \"U\"])\n",
    "\n",
    "            start_time = default_timer()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            U, V = model(data)\n",
    "            # Loss function\n",
    "            loss = loss_fcn(data, U, V)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_time = default_timer() - start_time\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # Print and save statistics\n",
    "            if i % batch_pr == batch_pr - 1:    # print every 200 mini-batches\n",
    "                avg_loss = running_loss / batch_pr \n",
    "                loss_arr.append(avg_loss)\n",
    "                avg_time = running_time / batch_pr\n",
    "                time_arr.append(avg_time)\n",
    "                \n",
    "                # Determine validation loss\n",
    "                model.eval()\n",
    "                model.train(False)\n",
    "                v_arr = []\n",
    "                for v_data in validation_dataloader:\n",
    "                    v_data = v_data.to(device)\n",
    "                    U_v, V_v = model(v_data)\n",
    "                    v_arr.append(loss_fcn(v_data, U_v, V_v).item())\n",
    "                validation_arr.append(np.mean(v_arr))\n",
    "                model.train(True)\n",
    "\n",
    "                # Write out stats\n",
    "                print(f\"[{e}, {i+1}] loss: {avg_loss}, validation loss: {validation_arr[-1]}, average train time (sec): {avg_time}\")\n",
    "                if writer:\n",
    "                    writer.add_scalars('Training vs. Validation Loss',\n",
    "                            { 'Training' : avg_loss, 'Validation' : validation_arr[-1] },\n",
    "                            e * len(train_dataloader) + i)\n",
    "                    writer.add_scalar('Average Train Time (s)', avg_time, e * len(train_dataloader) + i)\n",
    "                    writer.flush()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_time = 0.0\n",
    "\n",
    "            if profiler:\n",
    "                profiler.step()\n",
    "        \n",
    "        # Save output to checkpoint dict\n",
    "        if e % checkpoint_at == checkpoint_at - 1:\n",
    "            dt = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "            save = Checkpoint(mname, e, loss_arr, validation_arr, optimizer.state_dict(), time_arr)._asdict()\n",
    "            torch.save(save, os.path.join(output_run_dir, checkpoint_dict_str.format(machine, mname, dt)))\n",
    "            torch.save(model.state_dict(), os.path.join(output_run_dir, state_dict_str.format(machine, mname, dt)))\n",
    "            print(f\"Saved checkpoint for epoch {e}: {machine}_{mname}\")\n",
    "            loss_arr = []\n",
    "            validation_arr = []\n",
    "            time_arr = []\n",
    "\n",
    "    # Always save output at end\n",
    "    dt = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "    save = Checkpoint(mname, e, loss_arr, validation_arr, optimizer.state_dict(), time_arr)._asdict()\n",
    "    torch.save(save, os.path.join(output_run_dir, checkpoint_dict_str.format(machine, mname, dt)))\n",
    "    torch.save(model.state_dict(), os.path.join(output_run_dir, state_dict_str.format(machine, mname, dt)))\n",
    "    print(f\"Saved checkpoint for epoch {e}: {machine}_{mname}\")\n",
    "    \n",
    "    print('Finished Training')\n",
    "\n",
    " \n",
    "##  torch.nn.functional.pad(input, pad, mode='constant', value=None) → Tensor\n",
    "\n",
    "def trace_handler(prof):\n",
    "    table = prof.key_averages().table(sort_by=\"self_cuda_time_total\" if use_cuda else \"self_cpu_time_total\", row_limit=10)\n",
    "    print(table)\n",
    "    # ff = prof.key_averages()\n",
    "    # df_table = pd.DataFrame(ff)\n",
    "    # print(df_table)\n",
    "    # df_table.to_csv(\"tst.csv\")\n",
    "    \n",
    "    ## TODO: save to file, and tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f26d659-c6b3-4dce-b0b3-11038ecb9571",
   "metadata": {},
   "source": [
    "### Model hyperparameters to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8b62bf7-6b71-436d-99e7-65e019a1583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank = 10, \t sl=[500, 200], \t fl=[200, 300] Fork_r10_sdim2-3ebc_fdim2-37e7\n",
      "rank = 10, \t sl=[500, 200], \t fl=[200, 300, 400] Fork_r10_sdim2-3ebc_fdim3-1276\n",
      "rank = 10, \t sl=[600, 400, 200], \t fl=[200, 300] Fork_r10_sdim3-1420_fdim2-37e7\n",
      "rank = 10, \t sl=[600, 400, 200], \t fl=[200, 300, 400] Fork_r10_sdim3-1420_fdim3-1276\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "# ranks = (6, 10, 15)\n",
    "nn_rank = 10\n",
    "\n",
    "stem_layer_dims = [[500, 200],\n",
    "                   [600, 400, 200], \n",
    "                  ]\n",
    "fork_layer_dims = [[200, 300],\n",
    "                   [200, 300, 400]\n",
    "                  ]\n",
    "# Save details\n",
    "run_details = {}\n",
    "# for r in ranks:\n",
    "for sl in stem_layer_dims:\n",
    "    for fl in fork_layer_dims:\n",
    "        m = Fork(nn_rank, img_size, sl, fl).to(device)\n",
    "        print(f\"rank = {nn_rank}, \\t sl={sl}, \\t fl={fl}\", m.get_name())\n",
    "        models.append(m)\n",
    "        run_details[m.get_name()] = {\"rank\": nn_rank, \n",
    "                                     \"img_size\": img_size, \n",
    "                                     \"stem_layer_dims\": sl,\n",
    "                                     \"fork_layer_dims\": fl\n",
    "                                    }\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b04a6361-8621-4436-8940-a78617e944e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fork_r10_sdim2-3ebc_fdim2-37e7': {'rank': 10,\n",
       "  'img_size': (54, 96),\n",
       "  'stem_layer_dims': [500, 200],\n",
       "  'fork_layer_dims': [200, 300]},\n",
       " 'Fork_r10_sdim2-3ebc_fdim3-1276': {'rank': 10,\n",
       "  'img_size': (54, 96),\n",
       "  'stem_layer_dims': [500, 200],\n",
       "  'fork_layer_dims': [200, 300, 400]},\n",
       " 'Fork_r10_sdim3-1420_fdim2-37e7': {'rank': 10,\n",
       "  'img_size': (54, 96),\n",
       "  'stem_layer_dims': [600, 400, 200],\n",
       "  'fork_layer_dims': [200, 300]},\n",
       " 'Fork_r10_sdim3-1420_fdim3-1276': {'rank': 10,\n",
       "  'img_size': (54, 96),\n",
       "  'stem_layer_dims': [600, 400, 200],\n",
       "  'fork_layer_dims': [200, 300, 400]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1552edf3-c542-490c-bfa5-84a22d644d90",
   "metadata": {},
   "source": [
    "### Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c89cf0db-c20b-40ec-9f82-a4aeb8a8981d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fork_r10_sdim2-3ebc_fdim2-37e7\n",
      "Found checkpoint to load. Using: PC_Fork_r10_sdim2-3ebc_fdim2-37e7_checkpoint_2023-11-25_012609.tar\n",
      "Found model state dict to load. Using: PC_Fork_r10_sdim2-3ebc_fdim2-37e7_state-dict_2023-11-25_012609.pt\n",
      "[15, 200] loss: 0.0067654151224996895, validation loss: 0.007668236512032971, average train time (sec): 7.703500014031306e-06\n",
      "[15, 400] loss: 0.010658946471521632, validation loss: 0.008591344862220789, average train time (sec): 7.403999916277826e-06\n",
      "[15, 600] loss: 0.007711944729089737, validation loss: 0.007955258274641318, average train time (sec): 8.313500002259388e-06\n",
      "[15, 800] loss: 0.007098832654301077, validation loss: 0.008029912543902, average train time (sec): 7.46450008591637e-06\n",
      "[16, 200] loss: 0.007415096741169691, validation loss: 0.007764120101513251, average train time (sec): 7.333499961532653e-06\n",
      "[16, 400] loss: 0.00712463338044472, validation loss: 0.0077292728609990565, average train time (sec): 7.88649995229207e-06\n",
      "[16, 600] loss: 0.007344641966046766, validation loss: 0.007366222081027343, average train time (sec): 7.546000124420971e-06\n",
      "[16, 800] loss: 0.00649086125427857, validation loss: 0.007413505857851924, average train time (sec): 8.384999964619056e-06\n",
      "[17, 200] loss: 0.006527357082231902, validation loss: 0.006985552392581471, average train time (sec): 7.727999909548089e-06\n",
      "[17, 400] loss: 0.006972313481383025, validation loss: 0.007031008779057423, average train time (sec): 6.6639999567996714e-06\n",
      "[17, 600] loss: 0.006965624842559919, validation loss: 0.006971790028137041, average train time (sec): 8.029499877011404e-06\n",
      "[17, 800] loss: 0.0070293445035349575, validation loss: 0.007184740767440305, average train time (sec): 8.301999914692714e-06\n",
      "[18, 200] loss: 0.006551084429956972, validation loss: 0.007424248854601998, average train time (sec): 7.432499987771735e-06\n",
      "[18, 400] loss: 0.0070406569249462335, validation loss: 0.006999726145403619, average train time (sec): 7.19749994459562e-06\n",
      "[18, 600] loss: 0.006861402177019044, validation loss: 0.00690959654982136, average train time (sec): 7.367000071099028e-06\n",
      "[18, 800] loss: 0.006761829151073471, validation loss: 0.0069356648447026666, average train time (sec): 7.722000009380282e-06\n",
      "[19, 200] loss: 0.006488407070282847, validation loss: 0.007113480350161906, average train time (sec): 7.438000029651448e-06\n",
      "[19, 400] loss: 0.007076126302126795, validation loss: 0.007004597980778346, average train time (sec): 6.993999995756895e-06\n",
      "[19, 600] loss: 0.006694410408381373, validation loss: 0.0071785028939062665, average train time (sec): 7.5185000605415555e-06\n",
      "[19, 800] loss: 0.007443707623169757, validation loss: 0.0070778930834131, average train time (sec): 8.194999973056838e-06\n",
      "[20, 200] loss: 0.0064674657466821375, validation loss: 0.0070482039993774274, average train time (sec): 8.449000015389174e-06\n",
      "[20, 400] loss: 0.0069018597737886015, validation loss: 0.006986351736966645, average train time (sec): 7.4020000465679915e-06\n",
      "[20, 600] loss: 0.00705611178826075, validation loss: 0.007137658467453984, average train time (sec): 7.213000062620268e-06\n",
      "[20, 800] loss: 0.006612365993787534, validation loss: 0.006840752291434261, average train time (sec): 7.857500022510067e-06\n",
      "[21, 200] loss: 0.006735566236311569, validation loss: 0.007124117253604432, average train time (sec): 7.034500013105571e-06\n",
      "[21, 400] loss: 0.0068698179331840945, validation loss: 0.00684575131119724, average train time (sec): 7.597000076202676e-06\n",
      "[21, 600] loss: 0.006480559268966317, validation loss: 0.006756596407008299, average train time (sec): 7.788500079186634e-06\n",
      "[21, 800] loss: 0.006919710614602082, validation loss: 0.0067541703129997376, average train time (sec): 7.131500024115667e-06\n",
      "[22, 200] loss: 0.006749874353408814, validation loss: 0.0067665867587953085, average train time (sec): 6.786500016460195e-06\n",
      "[22, 400] loss: 0.00637972145283129, validation loss: 0.007140910295340264, average train time (sec): 7.918000046629458e-06\n",
      "[22, 600] loss: 0.0066151352785527705, validation loss: 0.007528718713702129, average train time (sec): 6.927500071469694e-06\n",
      "[22, 800] loss: 0.0071773662371560935, validation loss: 0.007230515810782194, average train time (sec): 7.4355000106152145e-06\n",
      "[23, 200] loss: 0.006350831345189363, validation loss: 0.0073488728354466895, average train time (sec): 6.676000048173591e-06\n",
      "[23, 400] loss: 0.006489063415210694, validation loss: 0.006685890781011114, average train time (sec): 8.055000071180985e-06\n",
      "[23, 600] loss: 0.006555134312948212, validation loss: 0.00664042294169101, average train time (sec): 7.83600000431761e-06\n",
      "[23, 800] loss: 0.0064269287115894256, validation loss: 0.00682188890836302, average train time (sec): 8.615999977337197e-06\n",
      "[24, 200] loss: 0.00605531224689912, validation loss: 0.0065627083027402985, average train time (sec): 7.272500079125166e-06\n",
      "[24, 400] loss: 0.006476418011588976, validation loss: 0.0075398933884192635, average train time (sec): 7.709000055911019e-06\n",
      "[24, 600] loss: 0.006913628492038697, validation loss: 0.006568607062769562, average train time (sec): 7.499500061385333e-06\n",
      "[24, 800] loss: 0.006641172370873392, validation loss: 0.006802728358521143, average train time (sec): 7.452500140061602e-06\n",
      "[25, 200] loss: 0.006647780385101214, validation loss: 0.006507858930010224, average train time (sec): 7.60049995733425e-06\n",
      "[25, 400] loss: 0.006212142445147038, validation loss: 0.006548871053382754, average train time (sec): 7.305000035557896e-06\n",
      "[25, 600] loss: 0.00616623714857269, validation loss: 0.006529550406074352, average train time (sec): 7.2349999391008165e-06\n",
      "[25, 800] loss: 0.0066582270874641835, validation loss: 0.00663339244946145, average train time (sec): 7.331500091822818e-06\n",
      "[26, 200] loss: 0.006132544994470663, validation loss: 0.006849966667589063, average train time (sec): 7.248500041896477e-06\n",
      "[26, 400] loss: 0.006510018772096373, validation loss: 0.006734399683686963, average train time (sec): 7.688999903621153e-06\n",
      "[26, 600] loss: 0.007176784597104416, validation loss: 0.006503717716329741, average train time (sec): 8.010500023374334e-06\n",
      "[26, 800] loss: 0.0064661425916710865, validation loss: 0.006386646209371218, average train time (sec): 7.192500052042306e-06\n",
      "[27, 200] loss: 0.006442784797982313, validation loss: 0.006370652004380513, average train time (sec): 7.750999939162285e-06\n",
      "[27, 400] loss: 0.006303687274339609, validation loss: 0.006447373220323131, average train time (sec): 7.223499997053296e-06\n",
      "[27, 600] loss: 0.005754785426543094, validation loss: 0.006427181494720003, average train time (sec): 7.072499865898862e-06\n",
      "[27, 800] loss: 0.005999806206091307, validation loss: 0.006429157363507052, average train time (sec): 7.329000072786584e-06\n",
      "[28, 200] loss: 0.006280722088413313, validation loss: 0.00666854194829372, average train time (sec): 7.189000025391579e-06\n",
      "[28, 400] loss: 0.006367340252618306, validation loss: 0.007119988099512641, average train time (sec): 8.95200006198138e-06\n",
      "[28, 600] loss: 0.006302820473792963, validation loss: 0.006402797774553687, average train time (sec): 7.64349999371916e-06\n",
      "[28, 800] loss: 0.006311297460924834, validation loss: 0.006512714506189259, average train time (sec): 7.316999981412664e-06\n",
      "[29, 200] loss: 0.00653380936535541, validation loss: 0.006344014221324575, average train time (sec): 7.523500098614022e-06\n",
      "[29, 400] loss: 0.005722502544522286, validation loss: 0.006357020036781338, average train time (sec): 7.165499991970136e-06\n",
      "[29, 600] loss: 0.006300878071924671, validation loss: 0.006440463941544294, average train time (sec): 7.296999974641949e-06\n",
      "[29, 800] loss: 0.006355058411136269, validation loss: 0.006653963337171144, average train time (sec): 8.04049996077083e-06\n",
      "Saved checkpoint for epoch 29: PC_Fork_r10_sdim2-3ebc_fdim2-37e7\n",
      "[30, 200] loss: 0.006451593266101554, validation loss: 0.0072385989857463645, average train time (sec): 8.092500065686181e-06\n",
      "[30, 400] loss: 0.006456506292452104, validation loss: 0.006466856170064842, average train time (sec): 1.0016500018537045e-05\n",
      "[30, 600] loss: 0.006226009827805683, validation loss: 0.006237595999045609, average train time (sec): 7.27299993741326e-06\n",
      "[30, 800] loss: 0.005934657560428605, validation loss: 0.006437440549515077, average train time (sec): 7.146999996621161e-06\n",
      "[31, 200] loss: 0.00612226574739907, validation loss: 0.006427952599085064, average train time (sec): 7.362500036833808e-06\n",
      "[31, 400] loss: 0.006174483181093819, validation loss: 0.006844902264826747, average train time (sec): 7.3364999843761325e-06\n",
      "[31, 600] loss: 0.006216263984679244, validation loss: 0.006977742166971601, average train time (sec): 7.067499973345548e-06\n",
      "[31, 800] loss: 0.006218269395176322, validation loss: 0.006555664324509776, average train time (sec): 8.93849995918572e-06\n",
      "[32, 200] loss: 0.0059302247426239775, validation loss: 0.006337459507696054, average train time (sec): 7.68350000726059e-06\n",
      "[32, 400] loss: 0.006205350552918389, validation loss: 0.006635568010340338, average train time (sec): 7.796499994583428e-06\n",
      "[32, 600] loss: 0.006128989453427494, validation loss: 0.0063855666134915, average train time (sec): 7.184999994933605e-06\n",
      "[32, 800] loss: 0.005733121397788636, validation loss: 0.0063606239907221945, average train time (sec): 1.0406000073999167e-05\n",
      "[33, 200] loss: 0.005943318653735332, validation loss: 0.006557661267499471, average train time (sec): 7.492000004276633e-06\n",
      "[33, 400] loss: 0.005851178339798935, validation loss: 0.006841514552995341, average train time (sec): 7.598500087624416e-06\n",
      "[33, 600] loss: 0.00615029749693349, validation loss: 0.006486929799031923, average train time (sec): 7.399000023724511e-06\n",
      "[33, 800] loss: 0.006408106244634837, validation loss: 0.006270287706876748, average train time (sec): 8.533499931218103e-06\n",
      "[34, 200] loss: 0.006187312947586179, validation loss: 0.006441935427750021, average train time (sec): 7.623999990755692e-06\n",
      "[34, 400] loss: 0.006260952957672998, validation loss: 0.006270711531353678, average train time (sec): 7.008999964455143e-06\n",
      "[34, 600] loss: 0.005964859168743715, validation loss: 0.006311369328032556, average train time (sec): 7.554000039817765e-06\n",
      "[34, 800] loss: 0.0058894570474512875, validation loss: 0.00610608123952599, average train time (sec): 8.2894999650307e-06\n",
      "Finished Training\n",
      "Training Fork_r10_sdim2-3ebc_fdim3-1276\n",
      "Found checkpoint to load. Using: PC_Fork_r10_sdim2-3ebc_fdim3-1276_checkpoint_2023-11-25_012730.tar\n",
      "Found model state dict to load. Using: PC_Fork_r10_sdim2-3ebc_fdim3-1276_state-dict_2023-11-25_012730.pt\n",
      "[15, 200] loss: 0.008546677778940647, validation loss: 0.008133023167998429, average train time (sec): 9.474499966017903e-06\n",
      "[15, 400] loss: 0.007067276265006512, validation loss: 0.00773433135168066, average train time (sec): 8.124000014504418e-06\n",
      "[15, 600] loss: 0.00800651975441724, validation loss: 0.007619089591507298, average train time (sec): 8.096499950625002e-06\n",
      "[15, 800] loss: 0.007303021792322398, validation loss: 0.0075373386957277595, average train time (sec): 1.0098500060848892e-05\n",
      "[16, 200] loss: 0.007470754497917369, validation loss: 0.007553175909680117, average train time (sec): 8.718000026419759e-06\n",
      "[16, 400] loss: 0.007442377773113549, validation loss: 0.007850347809514316, average train time (sec): 7.987999997567386e-06\n",
      "[16, 600] loss: 0.007699396662646904, validation loss: 0.007729392860527929, average train time (sec): 8.013500046217814e-06\n",
      "[16, 800] loss: 0.006961181805818342, validation loss: 0.008226629788035242, average train time (sec): 8.411000017076731e-06\n",
      "[17, 200] loss: 0.007555790608748793, validation loss: 0.007780341339751137, average train time (sec): 1.0064500092994422e-05\n",
      "[17, 400] loss: 0.008462225868133827, validation loss: 0.008890881853136598, average train time (sec): 9.298000077251344e-06\n",
      "[17, 600] loss: 0.006782501722336747, validation loss: 0.00838510148819245, average train time (sec): 8.907999872462824e-06\n",
      "[17, 800] loss: 0.008559913094504736, validation loss: 0.007578363259527209, average train time (sec): 8.265500073321163e-06\n",
      "[18, 200] loss: 0.007347778035327792, validation loss: 0.008432084913486718, average train time (sec): 7.86150005296804e-06\n",
      "[18, 400] loss: 0.007301947199739516, validation loss: 0.007279409124207818, average train time (sec): 8.276999869849533e-06\n",
      "[18, 600] loss: 0.006950897600036115, validation loss: 0.00732578105703481, average train time (sec): 7.84949996159412e-06\n",
      "[18, 800] loss: 0.008434874669183046, validation loss: 0.008504325890962077, average train time (sec): 9.774499922059477e-06\n",
      "[19, 200] loss: 0.008238983744522557, validation loss: 0.007874946152362072, average train time (sec): 7.868000102462247e-06\n",
      "[19, 400] loss: 0.007185824736370705, validation loss: 0.007327734075095435, average train time (sec): 7.678499969188124e-06\n",
      "[19, 600] loss: 0.006975551004870795, validation loss: 0.007846436055626401, average train time (sec): 8.72250006068498e-06\n",
      "[19, 800] loss: 0.007243553771404549, validation loss: 0.00946359789573681, average train time (sec): 8.159999997587875e-06\n",
      "[20, 200] loss: 0.0066614615230355416, validation loss: 0.007846831541844266, average train time (sec): 8.424499974353239e-06\n",
      "[20, 400] loss: 0.0073914602014701816, validation loss: 0.007906128774435158, average train time (sec): 7.970500009832903e-06\n",
      "[20, 600] loss: 0.007506845790776424, validation loss: 0.00772432863736546, average train time (sec): 8.093500073300674e-06\n",
      "[20, 800] loss: 0.007479127283440903, validation loss: 0.007777450622672208, average train time (sec): 8.75899990205653e-06\n",
      "[21, 200] loss: 0.007077947172801941, validation loss: 0.008036845115698929, average train time (sec): 1.1572000075830147e-05\n",
      "[21, 400] loss: 0.007126173552824184, validation loss: 0.008135729220515761, average train time (sec): 8.224000048357993e-06\n",
      "[21, 600] loss: 0.007808245637570508, validation loss: 0.007489108532445581, average train time (sec): 8.005499985301867e-06\n",
      "[21, 800] loss: 0.006913753980770707, validation loss: 0.00751625442337314, average train time (sec): 8.716500014998018e-06\n",
      "[22, 200] loss: 0.008015358355478383, validation loss: 0.007765317028457624, average train time (sec): 8.463499980280176e-06\n",
      "[22, 400] loss: 0.006865596771822311, validation loss: 0.007307297216908362, average train time (sec): 7.619999960297718e-06\n",
      "[22, 600] loss: 0.007185592078603804, validation loss: 0.007085307307375187, average train time (sec): 7.74000000092201e-06\n",
      "[22, 800] loss: 0.006681854975176975, validation loss: 0.006907350114082786, average train time (sec): 8.334500016644597e-06\n",
      "[23, 200] loss: 0.0070208543061744426, validation loss: 0.0069027987999502275, average train time (sec): 7.5520000245887785e-06\n",
      "[23, 400] loss: 0.006682984934886917, validation loss: 0.007135332743793061, average train time (sec): 8.53699995786883e-06\n",
      "[23, 600] loss: 0.007157475291169248, validation loss: 0.007140913840597946, average train time (sec): 8.476999937556684e-06\n",
      "[23, 800] loss: 0.007006105807377026, validation loss: 0.007038141812412519, average train time (sec): 8.19200009573251e-06\n",
      "[24, 200] loss: 0.006528535257093609, validation loss: 0.006937993191819652, average train time (sec): 8.43599991640076e-06\n",
      "[24, 400] loss: 0.007654710488859564, validation loss: 0.007161020914085736, average train time (sec): 8.22399990283884e-06\n",
      "[24, 600] loss: 0.007004425324848853, validation loss: 0.007540277215794117, average train time (sec): 8.73700002557598e-06\n",
      "[24, 800] loss: 0.006930630546412431, validation loss: 0.006979051104064713, average train time (sec): 8.50149997859262e-06\n",
      "[25, 200] loss: 0.00694426306115929, validation loss: 0.007199252920128322, average train time (sec): 8.109500049613416e-06\n",
      "[25, 400] loss: 0.006593490537488833, validation loss: 0.00697114210762776, average train time (sec): 9.692000021459535e-06\n",
      "[25, 600] loss: 0.006447022632928565, validation loss: 0.007239271275574501, average train time (sec): 9.919500007526949e-06\n",
      "[25, 800] loss: 0.007332744174636901, validation loss: 0.006819405348462548, average train time (sec): 8.578999986639247e-06\n",
      "[26, 200] loss: 0.007129852124489844, validation loss: 0.0070784985456532595, average train time (sec): 8.054999925661832e-06\n",
      "[26, 400] loss: 0.006640118795912713, validation loss: 0.006983010570490975, average train time (sec): 9.761499968590215e-06\n",
      "[26, 600] loss: 0.006635132567607798, validation loss: 0.006982514029714975, average train time (sec): 8.635499980300665e-06\n",
      "[26, 800] loss: 0.006436513876542449, validation loss: 0.006780312734147097, average train time (sec): 8.266999939223752e-06\n",
      "[27, 200] loss: 0.007244710716186091, validation loss: 0.00750037177109253, average train time (sec): 8.842999959597363e-06\n",
      "[27, 400] loss: 0.006648630148265511, validation loss: 0.006952588122293048, average train time (sec): 8.327000105055049e-06\n",
      "[27, 600] loss: 0.0067795909388223665, validation loss: 0.007068634759392381, average train time (sec): 8.258000016212463e-06\n",
      "[27, 800] loss: 0.006486064220080152, validation loss: 0.006865421826795408, average train time (sec): 9.982000046875327e-06\n",
      "[28, 200] loss: 0.006151612727553584, validation loss: 0.007245209243764831, average train time (sec): 1.564150006743148e-05\n",
      "[28, 400] loss: 0.007044857633300126, validation loss: 0.0071941523208563325, average train time (sec): 8.173499954864383e-06\n",
      "[28, 600] loss: 0.006699417033814825, validation loss: 0.0066739579837519995, average train time (sec): 8.441499958280473e-06\n",
      "[28, 800] loss: 0.0066922515537589785, validation loss: 0.00694044386287701, average train time (sec): 8.193499961635098e-06\n",
      "[29, 200] loss: 0.006725623507518322, validation loss: 0.00717813799289301, average train time (sec): 8.464999991701916e-06\n",
      "[29, 400] loss: 0.006754931301693432, validation loss: 0.006571383582476568, average train time (sec): 8.074499928625301e-06\n",
      "[29, 600] loss: 0.00660448978364002, validation loss: 0.006840867152676457, average train time (sec): 8.662500040372833e-06\n",
      "[29, 800] loss: 0.00664786767505575, validation loss: 0.0067043725330188705, average train time (sec): 8.206500060623512e-06\n",
      "Saved checkpoint for epoch 29: PC_Fork_r10_sdim2-3ebc_fdim3-1276\n",
      "[30, 200] loss: 0.006468762328731828, validation loss: 0.006654573233147259, average train time (sec): 7.933500019134953e-06\n",
      "[30, 400] loss: 0.006486838691635057, validation loss: 0.006797228257784613, average train time (sec): 8.265999931609257e-06\n",
      "[30, 600] loss: 0.006482194792479277, validation loss: 0.0070359874724455485, average train time (sec): 8.398500067414716e-06\n",
      "[30, 800] loss: 0.006615092456922866, validation loss: 0.007279057164769966, average train time (sec): 7.897499890532345e-06\n",
      "[31, 200] loss: 0.006935897298972122, validation loss: 0.0065427596557913106, average train time (sec): 7.469000120181591e-06\n",
      "[31, 400] loss: 0.00627238022221718, validation loss: 0.006559754801450166, average train time (sec): 8.451500034425408e-06\n",
      "[31, 600] loss: 0.006292679140460678, validation loss: 0.006714048487269302, average train time (sec): 8.47899995278567e-06\n",
      "[31, 800] loss: 0.006424356788629666, validation loss: 0.006772538252368736, average train time (sec): 8.642000029794871e-06\n",
      "[32, 200] loss: 0.006307723592617549, validation loss: 0.006719222776574467, average train time (sec): 8.259000023826957e-06\n",
      "[32, 400] loss: 0.006122937431791797, validation loss: 0.006536153944894727, average train time (sec): 8.463499980280176e-06\n",
      "[32, 600] loss: 0.006617145825293847, validation loss: 0.006925900558920293, average train time (sec): 8.722999918973073e-06\n",
      "[32, 800] loss: 0.006981179742724635, validation loss: 0.0070739978825721936, average train time (sec): 8.442999969702215e-06\n",
      "[33, 200] loss: 0.006153200761764311, validation loss: 0.006665783422327424, average train time (sec): 8.055000071180985e-06\n",
      "[33, 400] loss: 0.006279719391022809, validation loss: 0.0067601457963521044, average train time (sec): 1.0399500024504959e-05\n",
      "[33, 600] loss: 0.00666426578827668, validation loss: 0.00689218433740026, average train time (sec): 8.319499902427197e-06\n",
      "[33, 800] loss: 0.006909403257304802, validation loss: 0.007372081313510755, average train time (sec): 9.31749993469566e-06\n",
      "[34, 200] loss: 0.006137660989188589, validation loss: 0.00645813728435152, average train time (sec): 8.734000002732501e-06\n",
      "[34, 400] loss: 0.005822371307876892, validation loss: 0.006525764759841157, average train time (sec): 8.900999964680523e-06\n",
      "[34, 600] loss: 0.006688574047875591, validation loss: 0.00708582987930958, average train time (sec): 8.520999981556088e-06\n",
      "[34, 800] loss: 0.006830147473374381, validation loss: 0.007444264701321777, average train time (sec): 8.694499992998317e-06\n",
      "Finished Training\n",
      "Training Fork_r10_sdim3-1420_fdim2-37e7\n",
      "Found checkpoint to load. Using: PC_Fork_r10_sdim3-1420_fdim2-37e7_checkpoint_2023-11-25_012849.tar\n",
      "Found model state dict to load. Using: PC_Fork_r10_sdim3-1420_fdim2-37e7_state-dict_2023-11-25_012849.pt\n",
      "[15, 200] loss: 0.007359122190973721, validation loss: 0.00780865300765268, average train time (sec): 7.756999984849244e-06\n",
      "[15, 400] loss: 0.007698628759244457, validation loss: 0.00861157805201871, average train time (sec): 8.39899992570281e-06\n",
      "[15, 600] loss: 0.007914741348940879, validation loss: 0.007759931304692862, average train time (sec): 7.804500055499375e-06\n",
      "[15, 800] loss: 0.008116497687296942, validation loss: 0.008447169186028074, average train time (sec): 7.190000033006072e-06\n",
      "[16, 200] loss: 0.007474080314859748, validation loss: 0.008323282866347512, average train time (sec): 8.643000037409364e-06\n",
      "[16, 400] loss: 0.00777651212294586, validation loss: 0.008276771528985642, average train time (sec): 7.234500080812722e-06\n",
      "[16, 600] loss: 0.008194170544738881, validation loss: 0.00791993578740129, average train time (sec): 7.657499954802916e-06\n",
      "[16, 800] loss: 0.007396168127888814, validation loss: 0.008652629558391675, average train time (sec): 7.903999940026551e-06\n",
      "[17, 200] loss: 0.009001989469397812, validation loss: 0.00816047041708098, average train time (sec): 8.502499986207112e-06\n",
      "[17, 400] loss: 0.007568569005816244, validation loss: 0.0077769104845745686, average train time (sec): 8.339999913005159e-06\n",
      "[17, 600] loss: 0.007046257723122835, validation loss: 0.007822560839749679, average train time (sec): 8.068500028457492e-06\n",
      "[17, 800] loss: 0.007995492700720206, validation loss: 0.00794819114663981, average train time (sec): 8.789999992586672e-06\n",
      "[18, 200] loss: 0.008068221244029701, validation loss: 0.0076868469838994695, average train time (sec): 8.938500104704872e-06\n",
      "[18, 400] loss: 0.007311901880893856, validation loss: 0.007599909611125944, average train time (sec): 8.088500035228208e-06\n",
      "[18, 600] loss: 0.006950795169686898, validation loss: 0.0074199406199891215, average train time (sec): 8.337500039488077e-06\n",
      "[18, 800] loss: 0.0069587036658776925, validation loss: 0.007425530668223436, average train time (sec): 8.325999951921403e-06\n",
      "[19, 200] loss: 0.007955970109906048, validation loss: 0.008112132405606012, average train time (sec): 7.80350004788488e-06\n",
      "[19, 400] loss: 0.0072931770066497845, validation loss: 0.008536795168062569, average train time (sec): 7.679999980609863e-06\n",
      "[19, 600] loss: 0.007303225642535835, validation loss: 0.00804662807467203, average train time (sec): 7.334499969147146e-06\n",
      "[19, 800] loss: 0.0073795947921462355, validation loss: 0.007754152330403739, average train time (sec): 7.697999972151593e-06\n",
      "[20, 200] loss: 0.007374648953555152, validation loss: 0.0072586019644617595, average train time (sec): 7.63350006309338e-06\n",
      "[20, 400] loss: 0.007543333696667105, validation loss: 0.008036826603931676, average train time (sec): 7.545999978901818e-06\n",
      "[20, 600] loss: 0.007033609199570492, validation loss: 0.008006854460585073, average train time (sec): 8.132000075420365e-06\n",
      "[20, 800] loss: 0.007684267833828926, validation loss: 0.007863143766229647, average train time (sec): 7.851999980630352e-06\n",
      "[21, 200] loss: 0.006767823881236836, validation loss: 0.007143826348547821, average train time (sec): 7.454500009771437e-06\n",
      "[21, 400] loss: 0.007025094331474975, validation loss: 0.007576963647448745, average train time (sec): 7.78000001446344e-06\n",
      "[21, 600] loss: 0.00753028460952919, validation loss: 0.007413693845227056, average train time (sec): 7.585999992443249e-06\n",
      "[21, 800] loss: 0.0070017079520039265, validation loss: 0.007692174560158448, average train time (sec): 7.728500058874488e-06\n",
      "[22, 200] loss: 0.006582350741373375, validation loss: 0.006963526372205757, average train time (sec): 7.787000067764892e-06\n",
      "[22, 400] loss: 0.006763373493449762, validation loss: 0.007120640289737777, average train time (sec): 7.241999992402271e-06\n",
      "[22, 600] loss: 0.007002724289195612, validation loss: 0.007141076734628819, average train time (sec): 7.982499955687671e-06\n",
      "[22, 800] loss: 0.006999969142489135, validation loss: 0.00752107421504022, average train time (sec): 7.649999897694215e-06\n",
      "[23, 200] loss: 0.007412320081493817, validation loss: 0.00736726204722732, average train time (sec): 8.10300000011921e-06\n",
      "[23, 400] loss: 0.007120280315866694, validation loss: 0.008051777731966518, average train time (sec): 7.669499900657684e-06\n",
      "[23, 600] loss: 0.007761645793216303, validation loss: 0.00730506086818957, average train time (sec): 1.032799991662614e-05\n",
      "[23, 800] loss: 0.006792363550630398, validation loss: 0.0071681687477664485, average train time (sec): 7.909499981906264e-06\n",
      "[24, 200] loss: 0.007291156193823554, validation loss: 0.0070848860868796375, average train time (sec): 7.987499993760138e-06\n",
      "[24, 400] loss: 0.006614686838001944, validation loss: 0.007393150428071147, average train time (sec): 7.677499961573631e-06\n",
      "[24, 600] loss: 0.0063897397753316905, validation loss: 0.007535958318576411, average train time (sec): 8.574500097893179e-06\n",
      "[24, 800] loss: 0.006867159534594975, validation loss: 0.007344670004737615, average train time (sec): 7.2014999750535935e-06\n",
      "[25, 200] loss: 0.0070673491893103344, validation loss: 0.007856706989977551, average train time (sec): 7.96499996795319e-06\n",
      "[25, 400] loss: 0.007202900146367029, validation loss: 0.007755179584396788, average train time (sec): 7.580499950563535e-06\n",
      "[25, 600] loss: 0.007082352332072332, validation loss: 0.007596391900598338, average train time (sec): 7.918500050436706e-06\n",
      "[25, 800] loss: 0.0066353916912339625, validation loss: 0.006893719292027689, average train time (sec): 8.193000103347004e-06\n",
      "[26, 200] loss: 0.0067937059549149125, validation loss: 0.007024208694388294, average train time (sec): 7.704000017838552e-06\n",
      "[26, 400] loss: 0.006548081579967402, validation loss: 0.007582750778167498, average train time (sec): 7.502999942516908e-06\n",
      "[26, 600] loss: 0.0075580960419029, validation loss: 0.00978369811345515, average train time (sec): 7.5750000542029735e-06\n",
      "[26, 800] loss: 0.007661112645291723, validation loss: 0.00690727579826316, average train time (sec): 7.649500039406121e-06\n",
      "[27, 200] loss: 0.006734846906038001, validation loss: 0.006798348081000426, average train time (sec): 7.513000018661842e-06\n",
      "[27, 400] loss: 0.006658612038590945, validation loss: 0.0071372471621682435, average train time (sec): 7.719999994151294e-06\n",
      "[27, 600] loss: 0.006902881328715011, validation loss: 0.006815166530272055, average train time (sec): 7.431999983964488e-06\n",
      "[27, 800] loss: 0.006378876985399984, validation loss: 0.007143063336562324, average train time (sec): 7.684500014875083e-06\n",
      "[28, 200] loss: 0.006643462045467459, validation loss: 0.007432545761172711, average train time (sec): 8.591000078013167e-06\n",
      "[28, 400] loss: 0.0069103367708157745, validation loss: 0.007057175512830675, average train time (sec): 7.315999973798171e-06\n",
      "[28, 600] loss: 0.006891960117500275, validation loss: 0.00724758299978166, average train time (sec): 8.328999974764884e-06\n",
      "[28, 800] loss: 0.006722898931475357, validation loss: 0.007022993229710424, average train time (sec): 8.136499964166433e-06\n",
      "[29, 200] loss: 0.006965988914016634, validation loss: 0.007523057435736143, average train time (sec): 7.460499909939245e-06\n",
      "[29, 400] loss: 0.006843372110160999, validation loss: 0.007065675293656281, average train time (sec): 8.144000021275134e-06\n",
      "[29, 600] loss: 0.00684640348306857, validation loss: 0.0073316345392937556, average train time (sec): 8.420500089414418e-06\n",
      "[29, 800] loss: 0.006656299777678214, validation loss: 0.006858350075937143, average train time (sec): 8.240000024670735e-06\n",
      "Saved checkpoint for epoch 29: PC_Fork_r10_sdim3-1420_fdim2-37e7\n",
      "[30, 200] loss: 0.006553736562491395, validation loss: 0.0066099337844842815, average train time (sec): 7.576500065624714e-06\n",
      "[30, 400] loss: 0.0073881615587743, validation loss: 0.007047271510052969, average train time (sec): 7.240000122692436e-06\n",
      "[30, 600] loss: 0.006711283482727595, validation loss: 0.00677750307156057, average train time (sec): 7.52649997593835e-06\n",
      "[30, 800] loss: 0.005696198045043275, validation loss: 0.0066870601205536095, average train time (sec): 7.4970000423491e-06\n",
      "[31, 200] loss: 0.007143574698129668, validation loss: 0.007298550644688668, average train time (sec): 8.718500030227006e-06\n",
      "[31, 400] loss: 0.007464238747488707, validation loss: 0.007383818346072251, average train time (sec): 7.334000110859052e-06\n",
      "[31, 600] loss: 0.006744937023613602, validation loss: 0.007185703310094165, average train time (sec): 7.648500031791628e-06\n",
      "[31, 800] loss: 0.006414873612811789, validation loss: 0.006890895413356006, average train time (sec): 7.514500030083582e-06\n",
      "[32, 200] loss: 0.006430680851917714, validation loss: 0.006503604128731754, average train time (sec): 8.762000070419163e-06\n",
      "[32, 400] loss: 0.00626251476991456, validation loss: 0.006700874127094464, average train time (sec): 7.75749998865649e-06\n",
      "[32, 600] loss: 0.006829797119135037, validation loss: 0.006824961428090819, average train time (sec): 7.333999965339899e-06\n",
      "[32, 800] loss: 0.006525512426742352, validation loss: 0.007013757968041007, average train time (sec): 7.934500026749446e-06\n",
      "[33, 200] loss: 0.006227249163785018, validation loss: 0.006957966749050887, average train time (sec): 8.074999932432547e-06\n",
      "[33, 400] loss: 0.006385162342339754, validation loss: 0.007089244339400452, average train time (sec): 7.568500004708767e-06\n",
      "[33, 600] loss: 0.006696713350247591, validation loss: 0.006856064035619529, average train time (sec): 1.6030499973567204e-05\n",
      "[33, 800] loss: 0.006534323884407059, validation loss: 0.006490511441478665, average train time (sec): 8.188500069081782e-06\n",
      "[34, 200] loss: 0.006332257254980505, validation loss: 0.006683747646776219, average train time (sec): 7.794999983161687e-06\n",
      "[34, 400] loss: 0.006404907608521171, validation loss: 0.0072156004231166936, average train time (sec): 7.296499970834702e-06\n",
      "[34, 600] loss: 0.006746449800557457, validation loss: 0.006678183891093809, average train time (sec): 7.790999952703714e-06\n",
      "[34, 800] loss: 0.006946996918995865, validation loss: 0.006580805554414743, average train time (sec): 8.287500095320866e-06\n",
      "Finished Training\n",
      "Training Fork_r10_sdim3-1420_fdim3-1276\n",
      "Found checkpoint to load. Using: PC_Fork_r10_sdim3-1420_fdim3-1276_checkpoint_2023-11-25_013012.tar\n",
      "Found model state dict to load. Using: PC_Fork_r10_sdim3-1420_fdim3-1276_state-dict_2023-11-25_013012.pt\n",
      "[15, 200] loss: 0.008190236077643931, validation loss: 0.00908978216066181, average train time (sec): 9.094999986700714e-06\n",
      "[15, 400] loss: 0.008719245824031531, validation loss: 0.008573823546139059, average train time (sec): 8.992500079330057e-06\n",
      "[15, 600] loss: 0.008228412891039625, validation loss: 0.008555578660794627, average train time (sec): 9.025499894050881e-06\n",
      "[15, 800] loss: 0.008304906932171435, validation loss: 0.008365922406675868, average train time (sec): 1.1655500129563734e-05\n",
      "[16, 200] loss: 0.00845693634590134, validation loss: 0.009003731419529669, average train time (sec): 8.987000037450343e-06\n",
      "[16, 400] loss: 0.01001662935479544, validation loss: 0.009342122409271153, average train time (sec): 8.179500000551342e-06\n",
      "[16, 600] loss: 0.007826252047671005, validation loss: 0.009317432982902489, average train time (sec): 8.679000020492821e-06\n",
      "[16, 800] loss: 0.008956762437010183, validation loss: 0.008820995514464589, average train time (sec): 8.597999985795469e-06\n",
      "[17, 200] loss: 0.008844282833160832, validation loss: 0.009976899704885528, average train time (sec): 8.507500024279579e-06\n",
      "[17, 400] loss: 0.009574049776419997, validation loss: 0.018779912440722538, average train time (sec): 8.62300003063865e-06\n",
      "[17, 600] loss: 0.009956681597977877, validation loss: 0.009013798285178757, average train time (sec): 8.480499964207411e-06\n",
      "[17, 800] loss: 0.00790810580831021, validation loss: 0.00883995462555203, average train time (sec): 1.0072500008391217e-05\n",
      "[18, 200] loss: 0.007956576419528573, validation loss: 0.008504394999251711, average train time (sec): 8.529999904567376e-06\n",
      "[18, 400] loss: 0.008567240568809212, validation loss: 0.008068035869966485, average train time (sec): 8.296999876620248e-06\n",
      "[18, 600] loss: 0.007470695034717209, validation loss: 0.008431085702170337, average train time (sec): 9.16199991479516e-06\n",
      "[18, 800] loss: 0.008742011820431798, validation loss: 0.008455667369496978, average train time (sec): 1.0124499967787414e-05\n",
      "[19, 200] loss: 0.007276239306665957, validation loss: 0.008509891754237858, average train time (sec): 8.394500036956743e-06\n",
      "[19, 400] loss: 0.00834614695631899, validation loss: 0.008091201473436003, average train time (sec): 1.0073000012198464e-05\n",
      "[19, 600] loss: 0.007745271812891588, validation loss: 0.007923590433074085, average train time (sec): 8.870499877957627e-06\n",
      "[19, 800] loss: 0.008753513956908137, validation loss: 0.009960032448165644, average train time (sec): 9.512999968137592e-06\n",
      "[20, 200] loss: 0.008999735990073532, validation loss: 0.008930339424292727, average train time (sec): 8.941999985836447e-06\n",
      "[20, 400] loss: 0.007173780416487716, validation loss: 0.008660188851857273, average train time (sec): 8.6524999642279e-06\n",
      "[20, 600] loss: 0.008319599349051713, validation loss: 0.008713372926778233, average train time (sec): 9.192500001518056e-06\n",
      "[20, 800] loss: 0.008487579820211977, validation loss: 0.008761190816233813, average train time (sec): 1.1368499981472269e-05\n",
      "[21, 200] loss: 0.007898378652753309, validation loss: 0.008107882343599621, average train time (sec): 9.123999916482717e-06\n",
      "[21, 400] loss: 0.007852657784242182, validation loss: 0.009088520589890478, average train time (sec): 8.29249998787418e-06\n",
      "[21, 600] loss: 0.007992583441664465, validation loss: 0.008680210730102481, average train time (sec): 8.499500108882784e-06\n",
      "[21, 800] loss: 0.007422858994686976, validation loss: 0.0088037280184061, average train time (sec): 8.91599993337877e-06\n",
      "[22, 200] loss: 0.007871693312190474, validation loss: 0.008404318686422363, average train time (sec): 8.647499926155434e-06\n",
      "[22, 400] loss: 0.009009513704804704, validation loss: 0.008295049141749711, average train time (sec): 9.480500011704862e-06\n",
      "[22, 600] loss: 0.007617245935834944, validation loss: 0.007559908652629662, average train time (sec): 8.988500048872084e-06\n",
      "[22, 800] loss: 0.007272324295481667, validation loss: 0.007564830923536065, average train time (sec): 8.780999924056232e-06\n",
      "[23, 200] loss: 0.008996619409881532, validation loss: 0.009100898117914131, average train time (sec): 9.381999989273027e-06\n",
      "[23, 400] loss: 0.00816492831450887, validation loss: 0.008431570510965077, average train time (sec): 8.308499964186922e-06\n",
      "[23, 600] loss: 0.007773977229953743, validation loss: 0.007398867443875586, average train time (sec): 8.727500098757446e-06\n",
      "[23, 800] loss: 0.0071718876651721076, validation loss: 0.007541751033768446, average train time (sec): 9.720499947434292e-06\n",
      "[24, 200] loss: 0.007417010416975245, validation loss: 0.007834116432324163, average train time (sec): 8.698999881744384e-06\n",
      "[24, 400] loss: 0.008481731180800124, validation loss: 0.008031472903901372, average train time (sec): 8.72550008352846e-06\n",
      "[24, 600] loss: 0.00774942196207121, validation loss: 0.007359597032636986, average train time (sec): 8.556999964639545e-06\n",
      "[24, 800] loss: 0.006852948366431519, validation loss: 0.007384828288371235, average train time (sec): 8.56500002555549e-06\n",
      "[25, 200] loss: 0.007994625270366668, validation loss: 0.013951225362918911, average train time (sec): 8.658999868202954e-06\n",
      "[25, 400] loss: 0.007676614953670651, validation loss: 0.009112989169902075, average train time (sec): 9.586499945726246e-06\n",
      "[25, 600] loss: 0.00913801796035841, validation loss: 0.008552993278168003, average train time (sec): 8.931499905884266e-06\n",
      "[25, 800] loss: 0.007054156415397301, validation loss: 0.008342389646592138, average train time (sec): 8.242000039899722e-06\n",
      "[26, 200] loss: 0.007285408091847785, validation loss: 0.008231454051522102, average train time (sec): 8.827999990899116e-06\n",
      "[26, 400] loss: 0.007584145350847393, validation loss: 0.007601429504467015, average train time (sec): 8.647000067867338e-06\n",
      "[26, 600] loss: 0.007846759394742548, validation loss: 0.007266697014221527, average train time (sec): 1.0829999955603854e-05\n",
      "[26, 800] loss: 0.007126675508334302, validation loss: 0.007606275520308227, average train time (sec): 8.81999992998317e-06\n",
      "[27, 200] loss: 0.008490422905306333, validation loss: 0.008051586836804965, average train time (sec): 8.447000000160188e-06\n",
      "[27, 400] loss: 0.007784831783501431, validation loss: 0.007712892696372195, average train time (sec): 8.755500020924956e-06\n",
      "[27, 600] loss: 0.007010592345613987, validation loss: 0.008060253567155796, average train time (sec): 9.31350004975684e-06\n",
      "[27, 800] loss: 0.0073093183024320755, validation loss: 0.007894253204178522, average train time (sec): 8.483999990858138e-06\n",
      "[28, 200] loss: 0.0067052319040521976, validation loss: 0.007041679976116796, average train time (sec): 9.797499951673671e-06\n",
      "[28, 400] loss: 0.006628579774987884, validation loss: 0.0075577705281485415, average train time (sec): 8.86900001205504e-06\n",
      "[28, 600] loss: 0.007466587511589751, validation loss: 0.00854205859991199, average train time (sec): 9.122999908868224e-06\n",
      "[28, 800] loss: 0.007679311818210408, validation loss: 0.008355837526513076, average train time (sec): 8.759000047575683e-06\n",
      "[29, 200] loss: 0.007846997593296691, validation loss: 0.008253497681770904, average train time (sec): 8.555500098736957e-06\n",
      "[29, 400] loss: 0.007054643924348057, validation loss: 0.008065847631502329, average train time (sec): 8.656499994685874e-06\n",
      "[29, 600] loss: 0.006957262262003497, validation loss: 0.008226528387693307, average train time (sec): 8.891499892342835e-06\n",
      "[29, 800] loss: 0.007589927990920842, validation loss: 0.007516329871320952, average train time (sec): 9.105499921133741e-06\n",
      "Saved checkpoint for epoch 29: PC_Fork_r10_sdim3-1420_fdim3-1276\n",
      "[30, 200] loss: 0.006841759545495734, validation loss: 0.007932121011161948, average train time (sec): 8.688499947311357e-06\n",
      "[30, 400] loss: 0.007295496769365854, validation loss: 0.007528705434998338, average train time (sec): 9.238500060746446e-06\n",
      "[30, 600] loss: 0.007215399303240702, validation loss: 0.007620820437201393, average train time (sec): 8.83200002135709e-06\n",
      "[30, 800] loss: 0.009527120817219839, validation loss: 0.008747087738764054, average train time (sec): 9.16049990337342e-06\n",
      "[31, 200] loss: 0.006925972024910152, validation loss: 0.0077664021317774366, average train time (sec): 1.0604999988572673e-05\n",
      "[31, 400] loss: 0.007438707761466503, validation loss: 0.00725355801747274, average train time (sec): 9.100499883061274e-06\n",
      "[31, 600] loss: 0.006888952968874946, validation loss: 0.007205140739713958, average train time (sec): 8.7264999456238e-06\n",
      "[31, 800] loss: 0.006733799530775286, validation loss: 0.007342582729516973, average train time (sec): 8.545500022592024e-06\n",
      "[32, 200] loss: 0.006890922493766993, validation loss: 0.0070549505295363505, average train time (sec): 8.674999990034848e-06\n",
      "[32, 400] loss: 0.006685270431335084, validation loss: 0.00742064817673544, average train time (sec): 8.113499934552237e-06\n",
      "[32, 600] loss: 0.006843071815674193, validation loss: 0.007511428334026643, average train time (sec): 8.554999949410558e-06\n",
      "[32, 800] loss: 0.007351103659602814, validation loss: 0.00698963891226646, average train time (sec): 8.194000110961497e-06\n",
      "[33, 200] loss: 0.007491195336915553, validation loss: 0.00809604161138539, average train time (sec): 8.945500012487172e-06\n",
      "[33, 400] loss: 0.007611733642988838, validation loss: 0.007799129512465687, average train time (sec): 9.240999934263528e-06\n",
      "[33, 600] loss: 0.0069014331005746495, validation loss: 0.006777859503250971, average train time (sec): 9.107499936362729e-06\n",
      "[33, 800] loss: 0.00684822705690749, validation loss: 0.007090555973087877, average train time (sec): 8.701500046299771e-06\n",
      "[34, 200] loss: 0.006826488632941619, validation loss: 0.007153377259759489, average train time (sec): 9.523500048089772e-06\n",
      "[34, 400] loss: 0.006983363058534451, validation loss: 0.008042353479759456, average train time (sec): 9.668499988038093e-06\n",
      "[34, 600] loss: 0.009159562713466584, validation loss: 0.008226740326330785, average train time (sec): 9.75350005319342e-06\n",
      "[34, 800] loss: 0.0069243196293246, validation loss: 0.0068117506688696134, average train time (sec): 8.98750004125759e-06\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "run_details[\"run_params\"] = dict(epochs=20,\n",
    "                                 checkpoint_at=15,\n",
    "                                 batch_pr=200,\n",
    "                                 batch_size=batch_size,\n",
    "                                 subname=\"ED_Bigger\"\n",
    "                                )\n",
    "runname = run_details[\"run_params\"][\"subname\"]\n",
    "output_run_dir = os.path.join(output_dir, f\"run_{runname}\")\n",
    "# os.mkdir(output_run_dir)\n",
    "\n",
    "# Save details\n",
    "with open(os.path.join(output_run_dir, f\"details_{runname}.json\"), \"w\" ) as write:\n",
    "    json.dump(run_details, write, indent=2 )\n",
    "    \n",
    "\n",
    "for model in models:\n",
    "    writer = SummaryWriter(os.path.join(tensorboard_dir, f'{machine}_{model.get_name()}_{runname}'))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    train_model(model, optimizer, output_run_dir, **run_details[\"run_params\"], writer=writer, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df346cd8-400c-4862-a208-c0240bf79bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fork_r10_sdim2-3ebc_fdim2-37e7\n",
      "Found checkpoint to load. Using: PC_Fork_r10_sdim2-3ebc_fdim2-37e7_checkpoint_2023-11-25_015922.tar\n",
      "Found model state dict to load. Using: PC_Fork_r10_sdim2-3ebc_fdim2-37e7_state-dict_2023-11-25_015922.pt\n",
      "[45, 200] loss: 0.005357349325204268, validation loss: 0.0057996434408852824, average train time (sec): 7.89850004366599e-06\n",
      "[45, 400] loss: 0.006017538091400638, validation loss: 0.006033098203957524, average train time (sec): 7.52799998736009e-06\n",
      "[45, 600] loss: 0.005551546519855038, validation loss: 0.00599553467460032, average train time (sec): 1.0063499939860775e-05\n",
      "[45, 800] loss: 0.005698673369479366, validation loss: 0.005944059406092121, average train time (sec): 8.03050003014505e-06\n",
      "[46, 200] loss: 0.00569296455476433, validation loss: 0.005934577541716646, average train time (sec): 7.404000061796978e-06\n",
      "[46, 400] loss: 0.005421963929547928, validation loss: 0.005805185091937979, average train time (sec): 1.2510500091593713e-05\n",
      "[46, 600] loss: 0.005779234126675874, validation loss: 0.00601583485557355, average train time (sec): 7.250000053318218e-06\n",
      "[46, 800] loss: 0.005619619673816487, validation loss: 0.006008068728001034, average train time (sec): 7.448999967891723e-06\n",
      "[47, 200] loss: 0.006092779106693342, validation loss: 0.006213177787053457, average train time (sec): 7.168500014813617e-06\n",
      "[47, 400] loss: 0.005640885852044448, validation loss: 0.006029332617079652, average train time (sec): 7.68049998441711e-06\n",
      "[47, 600] loss: 0.005350987415877171, validation loss: 0.005857096952524687, average train time (sec): 9.523999906377867e-06\n",
      "[47, 800] loss: 0.005801965050632134, validation loss: 0.005969130288252129, average train time (sec): 7.101000082911924e-06\n",
      "[48, 200] loss: 0.005652898580301553, validation loss: 0.005900416009952089, average train time (sec): 7.113000028766692e-06\n",
      "[48, 400] loss: 0.005768503188737668, validation loss: 0.005787449876334671, average train time (sec): 7.257999968715012e-06\n",
      "[48, 600] loss: 0.00565882790077012, validation loss: 0.005841060305710148, average train time (sec): 1.766250003129244e-05\n",
      "[48, 800] loss: 0.005422551342635415, validation loss: 0.00573196225984846, average train time (sec): 8.198499999707565e-06\n",
      "[49, 200] loss: 0.0059473110409453515, validation loss: 0.006086397660743847, average train time (sec): 8.39500004076399e-06\n",
      "[49, 400] loss: 0.005910262974794023, validation loss: 0.005841537446673392, average train time (sec): 7.297499978449196e-06\n",
      "[49, 600] loss: 0.005485436737071723, validation loss: 0.005697598476586067, average train time (sec): 7.1725000452715905e-06\n",
      "[49, 800] loss: 0.0052769864583387975, validation loss: 0.005946336157851918, average train time (sec): 8.413499890593813e-06\n",
      "[50, 200] loss: 0.005447782895062119, validation loss: 0.005811346192813052, average train time (sec): 8.230999956140295e-06\n",
      "[50, 400] loss: 0.005340973826823756, validation loss: 0.005721885955470119, average train time (sec): 7.5325000216253105e-06\n",
      "[50, 600] loss: 0.005782406796352006, validation loss: 0.005717588307294427, average train time (sec): 7.711999933235347e-06\n",
      "[50, 800] loss: 0.00559689067187719, validation loss: 0.006090296122079307, average train time (sec): 7.523999956902117e-06\n",
      "[51, 200] loss: 0.0056947665783809494, validation loss: 0.005799536071769672, average train time (sec): 7.393499981844798e-06\n",
      "[51, 400] loss: 0.005666056769550778, validation loss: 0.005892838528864501, average train time (sec): 7.27149992599152e-06\n",
      "[51, 600] loss: 0.0058530117984628306, validation loss: 0.005853953911078104, average train time (sec): 7.5565000588539985e-06\n",
      "[51, 800] loss: 0.005060000500525348, validation loss: 0.005784617372542675, average train time (sec): 7.93250001152046e-06\n",
      "[52, 200] loss: 0.005800556898466311, validation loss: 0.0060186204989527295, average train time (sec): 7.786499918438494e-06\n",
      "[52, 400] loss: 0.005519194297376089, validation loss: 0.005847248956336048, average train time (sec): 7.750499935355038e-06\n",
      "[52, 600] loss: 0.00566631066321861, validation loss: 0.005939354925748778, average train time (sec): 7.3374999919906255e-06\n",
      "[52, 800] loss: 0.005782138100476004, validation loss: 0.005646697915034528, average train time (sec): 9.158000029856339e-06\n",
      "[53, 200] loss: 0.005798277705907822, validation loss: 0.0058752330237320976, average train time (sec): 8.89250004547648e-06\n",
      "[53, 400] loss: 0.005766336719389074, validation loss: 0.005811623673276719, average train time (sec): 7.3215000156778846e-06\n",
      "[53, 600] loss: 0.005637089006486348, validation loss: 0.00571764502189638, average train time (sec): 9.604500082787126e-06\n",
      "[53, 800] loss: 0.005178944555809722, validation loss: 0.005642722957364204, average train time (sec): 8.590499928686768e-06\n",
      "[54, 200] loss: 0.005632146568386815, validation loss: 0.0057522686307411985, average train time (sec): 7.686500030104071e-06\n",
      "[54, 400] loss: 0.00555528441153001, validation loss: 0.005861152981349083, average train time (sec): 7.726000039838255e-06\n",
      "[54, 600] loss: 0.005291161190834828, validation loss: 0.005795673212749697, average train time (sec): 7.16499998816289e-06\n",
      "[54, 800] loss: 0.005429721651016735, validation loss: 0.005990113136462424, average train time (sec): 2.0227500062901526e-05\n",
      "[55, 200] loss: 0.00563476585841272, validation loss: 0.005920583936195391, average train time (sec): 7.4055000732187185e-06\n",
      "[55, 400] loss: 0.005467759685125202, validation loss: 0.005865863661565662, average train time (sec): 7.753000099910423e-06\n",
      "[55, 600] loss: 0.005445901834173128, validation loss: 0.005810230553191723, average train time (sec): 7.071500003803522e-06\n",
      "[55, 800] loss: 0.005404207988758572, validation loss: 0.005779144612961487, average train time (sec): 7.465499948011711e-06\n",
      "[56, 200] loss: 0.005409369704429992, validation loss: 0.0056915019303871855, average train time (sec): 7.622499979333952e-06\n",
      "[56, 400] loss: 0.005377625813707709, validation loss: 0.005589191679804686, average train time (sec): 7.827999943401665e-06\n",
      "[56, 600] loss: 0.005781329246237874, validation loss: 0.0058838240456071484, average train time (sec): 7.4634999327827245e-06\n",
      "[56, 800] loss: 0.0053085045417537915, validation loss: 0.005569713277184858, average train time (sec): 7.85399999585934e-06\n",
      "[57, 200] loss: 0.005152424419648014, validation loss: 0.005813489551223177, average train time (sec): 8.420999947702512e-06\n",
      "[57, 400] loss: 0.005593186423066072, validation loss: 0.005781872316132054, average train time (sec): 8.29099997645244e-06\n",
      "[57, 600] loss: 0.005342877390794456, validation loss: 0.005707524595678296, average train time (sec): 7.328500068979338e-06\n",
      "[57, 800] loss: 0.0058660958707332615, validation loss: 0.006101912807164277, average train time (sec): 7.157000072766095e-06\n",
      "[58, 200] loss: 0.005412032308522612, validation loss: 0.0055568870849436545, average train time (sec): 7.070499996189028e-06\n",
      "[58, 400] loss: 0.005135228291619569, validation loss: 0.005604473436008931, average train time (sec): 7.437999884132296e-06\n",
      "[58, 600] loss: 0.005857409828458913, validation loss: 0.0057800706228428285, average train time (sec): 7.184999994933605e-06\n",
      "[58, 800] loss: 0.0053636689414270225, validation loss: 0.00560608091868017, average train time (sec): 7.268000044859945e-06\n",
      "[59, 200] loss: 0.005708376583643257, validation loss: 0.005528142230869115, average train time (sec): 7.41399999242276e-06\n",
      "[59, 400] loss: 0.00532883926993236, validation loss: 0.005519496698926123, average train time (sec): 7.202500128187239e-06\n",
      "[59, 600] loss: 0.005196978567983024, validation loss: 0.005537769813471401, average train time (sec): 7.2994999936781825e-06\n",
      "[59, 800] loss: 0.005325246294378303, validation loss: 0.005787680078329013, average train time (sec): 7.112500024959445e-06\n",
      "[60, 200] loss: 0.005451803057221696, validation loss: 0.0057806434745114425, average train time (sec): 7.376499997917562e-06\n",
      "[60, 400] loss: 0.005390580364037305, validation loss: 0.005819464805639837, average train time (sec): 7.460500055458396e-06\n",
      "[60, 600] loss: 0.0054460125183686614, validation loss: 0.0055442048867707415, average train time (sec): 8.847499993862583e-06\n",
      "[60, 800] loss: 0.005632762986933813, validation loss: 0.005945767445202405, average train time (sec): 8.926500013330952e-06\n",
      "[61, 200] loss: 0.005272034838562831, validation loss: 0.005587691187141914, average train time (sec): 7.311000081244856e-06\n",
      "[61, 400] loss: 0.005184768139151856, validation loss: 0.005583881578827104, average train time (sec): 8.542499999748543e-06\n",
      "[61, 600] loss: 0.005239954884746112, validation loss: 0.005620271772004276, average train time (sec): 7.02600009390153e-06\n",
      "[61, 800] loss: 0.0051459666312439365, validation loss: 0.0057433549155477695, average train time (sec): 7.400500035146251e-06\n",
      "[62, 200] loss: 0.005545416940003633, validation loss: 0.0058871131584214455, average train time (sec): 7.684500014875083e-06\n",
      "[62, 400] loss: 0.005537322382442653, validation loss: 0.00561799749136525, average train time (sec): 7.550000009359792e-06\n",
      "[62, 600] loss: 0.005355454400996678, validation loss: 0.005886735281643897, average train time (sec): 6.9904999691061676e-06\n",
      "[62, 800] loss: 0.0055538150225766005, validation loss: 0.005605612627445239, average train time (sec): 7.974999898578971e-06\n",
      "[63, 200] loss: 0.005131232302519492, validation loss: 0.005483254044642153, average train time (sec): 7.070499996189028e-06\n",
      "[63, 400] loss: 0.005461214111419394, validation loss: 0.005562904553979524, average train time (sec): 7.359000010183081e-06\n",
      "[63, 600] loss: 0.005279133030562662, validation loss: 0.00558062536091471, average train time (sec): 9.208999981638045e-06\n",
      "[63, 800] loss: 0.005658512166701257, validation loss: 0.006047366363114113, average train time (sec): 7.909999985713513e-06\n",
      "[64, 200] loss: 0.005225308421067894, validation loss: 0.005734331179652571, average train time (sec): 1.2161500053480268e-05\n",
      "[64, 400] loss: 0.005170440474757925, validation loss: 0.0056693030553298645, average train time (sec): 7.345000049099326e-06\n",
      "[64, 600] loss: 0.00577207040390931, validation loss: 0.0056365140667012075, average train time (sec): 7.582499965792522e-06\n",
      "[64, 800] loss: 0.005388189894729294, validation loss: 0.005661479778220829, average train time (sec): 7.289499917533249e-06\n",
      "Saved checkpoint for epoch 64: PC_Fork_r10_sdim2-3ebc_fdim2-37e7\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model = Fork(nn_rank, img_size, [500, 200], [200, 300]).to(device)\n",
    "\n",
    "\n",
    "\n",
    "writer = SummaryWriter(os.path.join(tensorboard_dir, f'{machine}_{model.get_name()}_{runname}'))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "# with profiler.profile(activities=[profiler.ProfilerActivity.CPU, profiler.ProfilerActivity.CUDA] if use_cuda else [profiler.ProfilerActivity.CPU],\n",
    "#                          record_shapes=False, \n",
    "#                          profile_memory=True, \n",
    "#                          # use_cuda=use_cuda,\n",
    "#                          schedule=torch.profiler.schedule(\n",
    "#                             wait=1,\n",
    "#                             warmup=1,\n",
    "#                             active=2,\n",
    "#                             repeat=1),\n",
    "#                          on_trace_ready=trace_handler\n",
    "#                          ) as prof:\n",
    "#         with profiler.record_function(\"train_model\"):\n",
    "#             train_model(15, model, optimizer, checkpoint_at=5, writer=writer, load=False, profiler=prof)\n",
    "\n",
    "            \n",
    "train_model(model, optimizer, output_run_dir, epochs=20, checkpoint_at=-1, writer=writer, load=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c02c138c-76b4-409f-a490-93aeb3744333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 % -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ead22-e9f7-4ddf-b784-f218099a0b77",
   "metadata": {},
   "source": [
    "### Setup to run against SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7106ac4-6e66-4dce-9f86-234a5b9a2c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model state dict to load. Using: PC_Fork_r10_sdim2-3ebc_fdim2-37e7_state-dict_2023-11-21_143047.pt\n",
      "Fork(\n",
      "  (input): Flatten(start_dim=1, end_dim=-1)\n",
      "  (seq): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=5184, out_features=500, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=500, out_features=200, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (U): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=200, out_features=300, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=300, out_features=540, bias=True)\n",
      "      (1): Unflatten(dim=1, unflattened_size=(54, 10))\n",
      "    )\n",
      "  )\n",
      "  (V): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=200, out_features=300, bias=True)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=300, out_features=960, bias=True)\n",
      "      (1): Unflatten(dim=1, unflattened_size=(10, 96))\n",
      "    )\n",
      "  )\n",
      ") Fork_r10_sdim2-3ebc_fdim2-37e7\n"
     ]
    }
   ],
   "source": [
    "# list(model_neg.parameters())\n",
    "# optimizer.__class__.__name__\n",
    "rank = 10\n",
    "stem_layer_dims=[500, 200] \n",
    "fork_layer_dims=[200, 300]\n",
    "\n",
    "model = Fork(nn_rank, img_size, stem_layer_dims, fork_layer_dims).to(device)\n",
    "\n",
    "_, statedict = load_checkpoint(model.get_name(), machine, output_run_dir=output_run_dir, checkpoint_str=\"\")\n",
    "model.load_state_dict(statedict)\n",
    "\n",
    "print(model, model.get_name())\n",
    "prof_events = None\n",
    "\n",
    "# def save_prof(prof):\n",
    "#     prof_events = prof.key_averages()\n",
    "\n",
    "# with profiler.profile(activities=[profiler.ProfilerActivity.CPU, profiler.ProfilerActivity.CUDA] if use_cuda else [profiler.ProfilerActivity.CPU],\n",
    "#                          record_shapes=False, \n",
    "#                          profile_memory=True,\n",
    "#                       on_trace_ready=save_prof\n",
    "#                          ) as prof:\n",
    "#     U, V = model(next(iter(validation_dataloader)))\n",
    "#     prof.step()\n",
    "#     prof_events = prof.key_averages()\n",
    "\n",
    "prof_events\n",
    "\n",
    "writer = SummaryWriter(os.path.join(tensorboard_dir, f'{machine}_{model.get_name()}_{runname}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76d7b26b-e137-4831-a708-7f479fc62a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb781738-f53a-4990-9a50-d4c5bff5b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "f= {\"F\": 2, \"G\": 4, \"d\": 6}\n",
    "for k in f:\n",
    "    print(k)\n",
    "\n",
    "print(int(\"5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2c681-0156-487e-916c-fa38f509e40f",
   "metadata": {},
   "source": [
    "## Comparision against base\n",
    "\n",
    "Compare against some python implementation of SVD that produces U: m x r V: r x n matrices\n",
    "\n",
    "<img src=\"images/rank_vs_err.png\" alt=\"Rank vs Error Plot\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "652e1d39-0482-477d-8477-de55cac5e786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = [1, 3, 4]\n",
    "np.array(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "251c35fe-fae7-4099-a20b-4218ea73c976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN:\n",
      " Loss (avg) = 0.0071444837 \tTime = 0.0022608256507920255\n",
      "Scipy SVD:\n",
      " Loss (avg) = 0.0050129476 \tTime = 0.006744099999574571\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# model = model_danmf\n",
    "svd_rank = 8\n",
    "# For tensorboard, to set what \"global step\" the histograms occured at\n",
    "step = 3\n",
    "losses_nn = []\n",
    "losses_svd = []\n",
    "times_nn = []\n",
    "times_svd = []\n",
    "\n",
    "\n",
    "# imgs = next(iter(validation_dataloader))\n",
    "\n",
    "for imgs in validation_dataloader:\n",
    "    imgs = imgs.to(device)\n",
    "    # Run and time the NN\n",
    "    start_nn = default_timer()\n",
    "    model.eval()\n",
    "    U_nn, V_nn = model(imgs)\n",
    "    U_nn = U_nn.cpu().detach().numpy()\n",
    "    V_nn = V_nn.cpu().detach().numpy()\n",
    "    UV_nn = np.maximum(np.matmul(U_nn, V_nn), 0)\n",
    "    end_nn = default_timer() - start_nn\n",
    "    times_nn.append(end_nn)\n",
    "\n",
    "    imgs = imgs.to(\"cpu\")\n",
    "    \n",
    "    # Run and time standard SVD, truncating to rank\n",
    "    svds = []\n",
    "    start_svd = default_timer()\n",
    "    for i in range(batch_size):\n",
    "        U_svd, S, V_svd = svd(imgs[i, :, :])\n",
    "        S = S[:svd_rank]\n",
    "        U_svd = U_svd[:, :svd_rank]\n",
    "        V_svd = V_svd[:svd_rank, :]\n",
    "        svds.append(U_svd.dot(diagsvd(S, svd_rank, svd_rank)).dot(V_svd))\n",
    "    end_svd = default_timer() - start_svd\n",
    "    times_svd.append(end_svd)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss_nn = np.square(np.linalg.norm(imgs - UV_nn, axis=(1, 2), ord=\"fro\"))\n",
    "    loss_svd = [np.square(np.linalg.norm(imgs[i, :, :] - svds[i], ord=\"fro\")) for i in range(batch_size)]\n",
    "    losses_nn.append(np.mean(loss_nn))\n",
    "    losses_svd.append(np.mean(loss_svd))\n",
    "\n",
    "writer.add_histogram(\"Model avg loss\", np.array(losses_nn), step)\n",
    "writer.add_histogram(\"SVD avg loss\", np.array(losses_svd), step)\n",
    "writer.add_histogram(\"Model time\", np.array(times_nn), step)\n",
    "writer.add_histogram(\"SVD time\", np.array(times_svd), step)\n",
    "writer.flush()\n",
    "\n",
    "print(\"SimpleNN:\\n\", \"Loss (avg) =\", np.mean(losses_nn), \"\\tTime =\", np.mean(times_nn))\n",
    "print(\"Scipy SVD:\\n\", \"Loss (avg) =\", np.mean(losses_svd), \"\\tTime =\", np.mean(times_svd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c660ae80-8521-4adb-8555-e0634ef57f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x142cb51e0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "U_svd, S, V_svd = svd(imgs[i, :, :])\n",
    "# plt.semilogy(S)\n",
    "plt.semilogy(np.sqrt(np.linalg.norm(S)**2 - np.cumsum(S**2)) / np.linalg.norm(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1648029f-e5aa-4ca5-99f4-b1ad04078edb",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* ~Save hyperparameters, run params to dict (json?)~\n",
    "* ~Run against bigger networks~\n",
    "* Compare rank vs err (loss) for SVD vs NN, and see how many more ranks it is to get comparable err\n",
    "    * compare against SVD 4, using rank 6 for NN (or bigger)\n",
    "* Use a different algo where we pre-give the rank, better alg: `scipy.sparse.linalg.svds`, tol=0.001\n",
    "* Go as big for imgs as I can, log space increase in size\n",
    "* Warm starting (initializing) the SVD algorithm, using the NN for the warm start\n",
    "    * `scipy.linalg.qr`\n",
    "* Randomized Numerical Linear Algebra: Foundations & Algorithms (Per-Gunnar Martinsson, University of Texas at Austin Joel A. Tropp, California Institute of Technology)\n",
    "\n",
    "\n",
    "## Model: Variations\n",
    "* ~Simple with no nonnegativity constraints (sigmoid activation)~\n",
    "    * ~Allow negativity at every step except after UV, aka ReLU(UV) or |UV| (relu better)~\n",
    "* ~Different activation layers~\n",
    "* ~Different structure~\n",
    "    * ~Try forking at beginning~\n",
    "* Define new layer\n",
    "    * Instead of flattening and using a linear layer, doing a either side multiply of the matrix input: A\\*X\\*B where A: n_1 x m, X: m x n, B: n x n_2\n",
    "* try 2d convolutional layers\n",
    "\n",
    "### Structure\n",
    "* Try dropout\n",
    "* Try regularization\n",
    "* Try different measured weight matrix sizes\n",
    "\n",
    "## Optional\n",
    "*  Pad input when not enough imgs for batch\n",
    "\n",
    "### Data Augmentation\n",
    "*  Cropping, rotating, scaling, reflecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b4b44f-e13c-4e04-a7a7-c25afd9bef5d",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e74a448-6846-44cc-bdf8-f3964cdd7a02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ad04aa25a33428de\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ad04aa25a33428de\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"../data/output/tensorboard\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c199b44d-598a-4a3f-be32-9e82ed3d3e55",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. <a id='r1'></a> De Handschutter, P., Gillis, N., & Siebert, X. (2021). A survey on deep matrix factorizations. Computer Science Review, 42, 100423. https://doi.org/10.1016/j.cosrev.2021.100423\n",
    "2. <a id='r2'></a> Sun, J., Kong, Q., & Xu, Z. (2022). Deep alternating non-negative matrix factorisation. Knowledge-Based Systems, 251, 109210. https://doi.org/10.1016/j.knosys.2022.109210\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64465e29-7aa1-4973-8eea-11ada04d614e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
