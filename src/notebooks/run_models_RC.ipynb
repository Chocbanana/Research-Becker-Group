{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675d1711-8d44-435d-b82c-604d3f89b9e9",
   "metadata": {},
   "source": [
    "# Run Models on RC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdde970-c7a3-4fcf-853c-fc567b66fcb5",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "632eb95f-72f6-4b11-84cd-33e48e92968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required packages\n",
    "#!pip install \"../reqiurements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb475e0-2bfc-4d6a-aa9d-20dbb7eb0712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T19:26:32.880633Z",
     "iopub.status.busy": "2023-12-19T19:26:32.880181Z",
     "iopub.status.idle": "2023-12-19T19:26:33.002227Z",
     "shell.execute_reply": "2023-12-19T19:26:33.001143Z",
     "shell.execute_reply.started": "2023-12-19T19:26:32.880606Z"
    }
   },
   "outputs": [],
   "source": [
    "# In order to force reload any changes done to the models package files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71ee3260-ccd2-4aa0-8283-13160a839398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T23:11:40.159775Z",
     "iopub.status.busy": "2023-12-19T23:11:40.159494Z",
     "iopub.status.idle": "2023-12-19T23:11:40.471530Z",
     "shell.execute_reply": "2023-12-19T23:11:40.470922Z",
     "shell.execute_reply.started": "2023-12-19T23:11:40.159753Z"
    }
   },
   "outputs": [],
   "source": [
    "## Allow import from our custom lib python files\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(os.path.join(module_path, \"lib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28295ed2-731a-4b1c-9573-9f19df5f96e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T23:11:41.483306Z",
     "iopub.status.busy": "2023-12-19T23:11:41.483001Z",
     "iopub.status.idle": "2023-12-19T23:11:41.535595Z",
     "shell.execute_reply": "2023-12-19T23:11:41.534708Z",
     "shell.execute_reply.started": "2023-12-19T23:11:41.483282Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from models.simpleFork import Simple, Fork\n",
    "from models.danmf import DANMF\n",
    "from models.convmf import ConvMF\n",
    "from datasets.gen_plasma_1d import GenPlasma1DDataset\n",
    "from framework.saveload import load_checkpoint, load_trained_model\n",
    "from framework.params import * # device, use_cuda, Checkpoint, various saving strs\n",
    "from framework.train import train_model\n",
    "\n",
    "from timeit import default_timer\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import onnx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd, diagsvd\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5cde01-0aeb-41f8-8ae3-9bf8c09959e0",
   "metadata": {},
   "source": [
    "### Per-run user defined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1961e23a-445b-4ba6-ada1-3366473f66c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T23:11:48.558290Z",
     "iopub.status.busy": "2023-12-19T23:11:48.557662Z",
     "iopub.status.idle": "2023-12-19T23:11:48.624876Z",
     "shell.execute_reply": "2023-12-19T23:11:48.623715Z",
     "shell.execute_reply.started": "2023-12-19T23:11:48.558263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Define the machine being used\n",
    "machine = \"RC\"\n",
    "\n",
    "# TODO: change for RC\n",
    "data_dir = os.path.join(\"..\", \"..\", \"data\")\n",
    "output_dir = os.path.join(data_dir, \"output\")\n",
    "# output_dir = os.path.join(\"projects\", \"bhjo6995\", \"output\")\n",
    "tensorboard_dir = os.path.join(output_dir, \"tensorboard\")\n",
    "\n",
    "# Dataset params\n",
    "batch_size = 25\n",
    "mat_size = [64, 128]\n",
    "mat_dirs = [os.path.join(data_dir, \"gen_plasma_n64\", f\"mat_{i}\") for i in range(3)]\n",
    "\n",
    "# Device comes from framework.params\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf874b-645d-4c00-83cb-3295843464c8",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "Data generated from the matlab code `gen_data_matlab/SSPML_CWENO_ht1d.m`\n",
    "\n",
    "#### Normalization\n",
    "* No normalization (too expensive?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d82384c-93c9-4e52-9158-c1ac31218743",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61ec189b-9ed7-4809-8cec-c7cc75b6b3a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T19:54:43.123819Z",
     "iopub.status.busy": "2023-12-19T19:54:43.123473Z",
     "iopub.status.idle": "2023-12-19T19:54:43.334690Z",
     "shell.execute_reply": "2023-12-19T19:54:43.334011Z",
     "shell.execute_reply.started": "2023-12-19T19:54:43.123793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and split the data, and prep for being fed into the NN\n",
    "data = GenPlasma1DDataset(mat_dirs)\n",
    "# Divide data into train, validation, test\n",
    "train_data, validation_data, test_data = random_split(data, [0.7, 0.2, 0.1], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, pin_memory=(torch.cuda.is_available()), drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_data, batch_size=batch_size, shuffle=True, pin_memory=(torch.cuda.is_available()), drop_last=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab1d863b-d541-4b73-aa75-ce19a38c8b05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T19:54:49.854187Z",
     "iopub.status.busy": "2023-12-19T19:54:49.853641Z",
     "iopub.status.idle": "2023-12-19T19:54:50.270587Z",
     "shell.execute_reply": "2023-12-19T19:54:50.269810Z",
     "shell.execute_reply.started": "2023-12-19T19:54:49.854144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21975 <class 'torch.Tensor'> torch.Size([64, 128])\n",
      "tensor([[ 1.5490e-09,  1.2974e-08, -1.2685e-09,  ..., -3.1265e-08,\n",
      "          2.4354e-08, -4.3778e-09],\n",
      "        [ 8.8028e-09,  6.6438e-09,  1.6978e-08,  ..., -1.7247e-08,\n",
      "          1.6309e-08,  3.0742e-10],\n",
      "        [ 1.4042e-08,  5.9671e-09,  2.7655e-08,  ...,  1.7584e-08,\n",
      "         -6.1634e-10,  7.9415e-09],\n",
      "        ...,\n",
      "        [ 2.9151e-10,  1.6614e-08, -1.7626e-08,  ...,  1.8026e-08,\n",
      "          6.2687e-09,  8.9249e-09],\n",
      "        [-4.8291e-09,  2.5087e-08, -3.2353e-08,  ..., -1.9762e-09,\n",
      "          1.3646e-08,  1.1134e-09],\n",
      "        [-4.2047e-09,  2.1915e-08, -2.2832e-08,  ..., -2.3230e-08,\n",
      "          2.2154e-08, -4.1802e-09]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[2669])\n",
    "print(len(data), type(data[0]), data[244].shape)\n",
    "print(data[2000])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8fd5925-3dde-43fb-bb48-cb34a28179f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "### Loss Function\n",
    "We use methods defined in [[1]](#r1) to define our loss function <!-- $\\mathcal{L}$ \\\\ -->\n",
    "\n",
    "$$\n",
    "\\min_{\\substack{U \\in \\real^{m\\times r} \\\\ V \\in \\real^{r\\times n}}} ||X - ReLU(UV)||^2_F ,\n",
    "$$\n",
    "Where we are finding the square Frobenius norm of the difference between the original matrix $X$ and the rectified linear low rank representation matrices $UV$\n",
    "\n",
    "### Optimizer\n",
    "\n",
    "Adam works fine / is standard\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e88ef72-8831-4488-9a7a-4211d0c43296",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ec560-b304-444a-9aa8-8a3daf1b1123",
   "metadata": {},
   "source": [
    "### Multiple models hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23d77c70-0bf9-4d0a-a6d2-6f7191cb1192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T23:35:33.760431Z",
     "iopub.status.busy": "2023-12-19T23:35:33.759804Z",
     "iopub.status.idle": "2023-12-19T23:35:34.170241Z",
     "shell.execute_reply": "2023-12-19T23:35:34.169599Z",
     "shell.execute_reply.started": "2023-12-19T23:35:33.760326Z"
    }
   },
   "outputs": [],
   "source": [
    "## Params\n",
    "ranks = [6, 12]\n",
    "\n",
    "stem_layer_dims = [500, 200]\n",
    "\n",
    "fork_layer_dims = [200, 300]\n",
    "\n",
    "conv_dims = [[5, 1, 3, 1], [3, 1, 0, 1]]\n",
    "\n",
    "run_params = dict(\n",
    "                epochs=120,\n",
    "                checkpoint_at=40,\n",
    "                batch_pr=40,\n",
    "                batch_size=batch_size,\n",
    "                subname=\"plasma_mf_test_1\"\n",
    "                )\n",
    "\n",
    "\n",
    "# Save details\n",
    "run_details = {\"run_params\": run_params}\n",
    "runname = run_details[\"run_params\"][\"subname\"]\n",
    "output_run_dir = os.path.join(output_dir, f\"run_{runname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ade524-8890-4669-88a1-d83596ed1608",
   "metadata": {},
   "source": [
    "### Models Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8b62bf7-6b71-436d-99e7-65e019a1583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fork_r4_sdim2-3ebc_fdim2-37e7 \trank = 4 \t sl=[500, 200] \t fl=[200, 300] \tcl=0\n",
      "ConvMF_r4_cdim2-c00f \trank = 4 \t sl=[500, 200] \t fl=[200, 300] \tcl=[[5, 1, 3, 1], [3, 1, 0, 1]]\n",
      "Fork_r5_sdim2-3ebc_fdim2-37e7 \trank = 5 \t sl=[500, 200] \t fl=[200, 300] \tcl=0\n",
      "ConvMF_r5_cdim2-c00f \trank = 5 \t sl=[500, 200] \t fl=[200, 300] \tcl=[[5, 1, 3, 1], [3, 1, 0, 1]]\n",
      "Fork_sdim2-3ebc_fdim2-37e7 \trank = 6 \t sl=[500, 200] \t fl=[200, 300] \tcl=0\n",
      "ConvMF_cdim2-c00f \trank = 6 \t sl=[500, 200] \t fl=[200, 300] \tcl=[[5, 1, 3, 1], [3, 1, 0, 1]]\n",
      "Fork_r7_sdim2-3ebc_fdim2-37e7 \trank = 7 \t sl=[500, 200] \t fl=[200, 300] \tcl=0\n",
      "ConvMF_r7_cdim2-c00f \trank = 7 \t sl=[500, 200] \t fl=[200, 300] \tcl=[[5, 1, 3, 1], [3, 1, 0, 1]]\n",
      "Fork_r8_sdim2-3ebc_fdim2-37e7 \trank = 8 \t sl=[500, 200] \t fl=[200, 300] \tcl=0\n",
      "ConvMF_r8_cdim2-c00f \trank = 8 \t sl=[500, 200] \t fl=[200, 300] \tcl=[[5, 1, 3, 1], [3, 1, 0, 1]]\n",
      "Fork_r9_sdim2-3ebc_fdim2-37e7 \trank = 9 \t sl=[500, 200] \t fl=[200, 300] \tcl=0\n",
      "ConvMF_r9_cdim2-c00f \trank = 9 \t sl=[500, 200] \t fl=[200, 300] \tcl=[[5, 1, 3, 1], [3, 1, 0, 1]]\n",
      "Fork_r10_sdim2-3ebc_fdim2-37e7 \trank = 10 \t sl=[500, 200] \t fl=[200, 300] \tcl=0\n",
      "ConvMF_r10_cdim2-c00f \trank = 10 \t sl=[500, 200] \t fl=[200, 300] \tcl=[[5, 1, 3, 1], [3, 1, 0, 1]]\n",
      "Fork_r11_sdim2-3ebc_fdim2-37e7 \trank = 11 \t sl=[500, 200] \t fl=[200, 300] \tcl=0\n",
      "ConvMF_r11_cdim2-c00f \trank = 11 \t sl=[500, 200] \t fl=[200, 300] \tcl=[[5, 1, 3, 1], [3, 1, 0, 1]]\n",
      "Fork_r12_sdim2-3ebc_fdim2-37e7 \trank = 12 \t sl=[500, 200] \t fl=[200, 300] \tcl=0\n",
      "ConvMF_r12_cdim2-c00f \trank = 12 \t sl=[500, 200] \t fl=[200, 300] \tcl=[[5, 1, 3, 1], [3, 1, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for r in ranks:\n",
    "    m = Fork(r, img_size, stem_layer_dims, fork_layer_dims).to(device)\n",
    "    print(f\"{m.get_name()} \\trank = {r} \\t sl={stem_layer_dims} \\t fl={fork_layer_dims} \\tcl={0}\")\n",
    "    models.append(m)\n",
    "    run_details[m.get_name()] = m.get_hyperparameters()\n",
    "\n",
    "    m = ConvMF(r, img_size, stem_layer_dims, fork_layer_dims, conv_dims).to(device)\n",
    "    print(f\"{m.get_name()} \\trank = {r} \\t sl={stem_layer_dims} \\t fl={fork_layer_dims} \\tcl={conv_dims}\")\n",
    "    models.append(m)\n",
    "    run_details[m.get_name()] = m.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47453944-254c-480c-8f73-e7653132b7cc",
   "metadata": {},
   "source": [
    "## Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c89cf0db-c20b-40ec-9f82-a4aeb8a8981d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ConvMF_r12_cdim2-c00f\n",
      "Found checkpoint to load. Using: PC_ConvMF_r12_cdim2-c00f_checkpoint_2023-11-27_032136.tar\n",
      "Found model state dict to load. Using: PC_ConvMF_r12_cdim2-c00f_state-dict_2023-11-27_032136.pt\n",
      "[80, 40] loss: 0.005513838154729456, validation loss: 0.005583635891594415, average train time (sec): 0.0001989050000005932\n",
      "[80, 80] loss: 0.005673635780112818, validation loss: 0.005567064157353257, average train time (sec): 5.328750000046512e-05\n",
      "[80, 120] loss: 0.006264014943735674, validation loss: 0.007470091444633479, average train time (sec): 5.661000000003469e-05\n",
      "[80, 160] loss: 0.00872987158363685, validation loss: 0.006559977114622323, average train time (sec): 5.2627499999857716e-05\n",
      "[81, 40] loss: 0.006696912960615009, validation loss: 0.007073415188505402, average train time (sec): 4.710999999986143e-05\n",
      "[81, 80] loss: 0.006672021996928379, validation loss: 0.005752058379035795, average train time (sec): 4.2834999999286086e-05\n",
      "[81, 120] loss: 0.005777103640139103, validation loss: 0.005563334517954093, average train time (sec): 4.6467500000346716e-05\n",
      "[81, 160] loss: 0.0052797061507590115, validation loss: 0.005502663117851007, average train time (sec): 4.867749999988291e-05\n",
      "[82, 40] loss: 0.0055759783019311724, validation loss: 0.005446507107853046, average train time (sec): 4.7740000000828785e-05\n",
      "[82, 80] loss: 0.0053256315586622804, validation loss: 0.005443142234997929, average train time (sec): 4.714250000006359e-05\n",
      "[82, 120] loss: 0.005581398634240032, validation loss: 0.005460396053199217, average train time (sec): 4.7152500000891e-05\n",
      "[82, 160] loss: 0.005195353977615014, validation loss: 0.005387706304285323, average train time (sec): 4.31574999993245e-05\n",
      "[83, 40] loss: 0.005445626401342452, validation loss: 0.005420003481701297, average train time (sec): 5.416499999881808e-05\n",
      "[83, 80] loss: 0.005692870548227802, validation loss: 0.005432497529875276, average train time (sec): 4.737249999919868e-05\n",
      "[83, 120] loss: 0.005355823348509148, validation loss: 0.0053490178685916484, average train time (sec): 4.795499999943331e-05\n",
      "[83, 160] loss: 0.005322708829771728, validation loss: 0.005436568582465626, average train time (sec): 4.678250000011985e-05\n",
      "[84, 40] loss: 0.005398555332794786, validation loss: 0.005447645443228056, average train time (sec): 4.520250000012993e-05\n",
      "[84, 80] loss: 0.006030811910750345, validation loss: 0.005485683178775153, average train time (sec): 4.785999999938895e-05\n",
      "[84, 120] loss: 0.0054261989251244815, validation loss: 0.005520985250906, average train time (sec): 4.662500000023329e-05\n",
      "[84, 160] loss: 0.005094395554624498, validation loss: 0.005374339800152295, average train time (sec): 5.009999999998627e-05\n",
      "[85, 40] loss: 0.005364105524495244, validation loss: 0.005368851911592877, average train time (sec): 4.474250000043867e-05\n",
      "[85, 80] loss: 0.005369815928861499, validation loss: 0.005390818481210549, average train time (sec): 4.72500000000764e-05\n",
      "[85, 120] loss: 0.005694269493687898, validation loss: 0.005377336730301942, average train time (sec): 4.586499999987836e-05\n",
      "[85, 160] loss: 0.005288675450719893, validation loss: 0.005374448391485889, average train time (sec): 4.5885000000112085e-05\n",
      "[86, 40] loss: 0.005296719097532332, validation loss: 0.005355879453555593, average train time (sec): 4.625500000088323e-05\n",
      "[86, 80] loss: 0.005335518880747259, validation loss: 0.0053436738737630395, average train time (sec): 4.635250000006863e-05\n",
      "[86, 120] loss: 0.005357010423904285, validation loss: 0.005362652756168314, average train time (sec): 5.041500000118049e-05\n",
      "[86, 160] loss: 0.005365429114317521, validation loss: 0.005324796984358778, average train time (sec): 4.987749999969537e-05\n",
      "[87, 40] loss: 0.005507553456118331, validation loss: 0.005338232380004143, average train time (sec): 5.367750000004889e-05\n",
      "[87, 80] loss: 0.005249375751009211, validation loss: 0.005334567269837519, average train time (sec): 6.536000000068043e-05\n",
      "[87, 120] loss: 0.005036852182820439, validation loss: 0.005284158341621734, average train time (sec): 4.551000000105887e-05\n",
      "[87, 160] loss: 0.0053589975752402095, validation loss: 0.005296695630399967, average train time (sec): 4.8537499999667943e-05\n",
      "[88, 40] loss: 0.00558882457553409, validation loss: 0.005998174558868105, average train time (sec): 5.050249999953849e-05\n",
      "[88, 80] loss: 0.0057027889066375795, validation loss: 0.005461501361767076, average train time (sec): 4.53250000006733e-05\n",
      "[88, 120] loss: 0.005452385806711391, validation loss: 0.005380227577538704, average train time (sec): 5.0752500000328384e-05\n",
      "[88, 160] loss: 0.005421828688122332, validation loss: 0.005274958289140519, average train time (sec): 5.018749999976535e-05\n",
      "[89, 40] loss: 0.005140982364537194, validation loss: 0.005290985467650418, average train time (sec): 5.570499999976164e-05\n",
      "[89, 80] loss: 0.005357919726520777, validation loss: 0.005238662798941697, average train time (sec): 4.674500000021453e-05\n",
      "[89, 120] loss: 0.0051249545183964075, validation loss: 0.00522713403147206, average train time (sec): 4.8742500000287235e-05\n",
      "[89, 160] loss: 0.005379729019477963, validation loss: 0.005287422991867336, average train time (sec): 4.8920000000407524e-05\n",
      "[90, 40] loss: 0.005042434425558895, validation loss: 0.005240300090386058, average train time (sec): 5.244250000089323e-05\n",
      "[90, 80] loss: 0.005381016386672854, validation loss: 0.005243940401892617, average train time (sec): 5.0324999999418194e-05\n",
      "[90, 120] loss: 0.005859064904507249, validation loss: 0.005508463829755783, average train time (sec): 4.530500000043958e-05\n",
      "[90, 160] loss: 0.005248687241692096, validation loss: 0.005329322100634563, average train time (sec): 4.92024999999785e-05\n",
      "[91, 40] loss: 0.006216440221760422, validation loss: 0.005395654452753798, average train time (sec): 4.689750000039794e-05\n",
      "[91, 80] loss: 0.0052447913913056254, validation loss: 0.005286728009968152, average train time (sec): 4.793499999919959e-05\n",
      "[91, 120] loss: 0.005658242356730625, validation loss: 0.005390999043571218, average train time (sec): 4.500000000007276e-05\n",
      "[91, 160] loss: 0.0059669153997674584, validation loss: 0.005297671911253963, average train time (sec): 5.026249999957599e-05\n",
      "[92, 40] loss: 0.005109316803282127, validation loss: 0.005237817491914304, average train time (sec): 4.5262499999410013e-05\n",
      "[92, 80] loss: 0.004952150542521849, validation loss: 0.005172676701133825, average train time (sec): 4.5740000000193956e-05\n",
      "[92, 120] loss: 0.005427213927032426, validation loss: 0.0051680276969904605, average train time (sec): 4.73124999999186e-05\n",
      "[92, 160] loss: 0.005190006399061531, validation loss: 0.005188334390591338, average train time (sec): 4.7759999999641424e-05\n",
      "[93, 40] loss: 0.005330901953857392, validation loss: 0.005213851798852941, average train time (sec): 4.590749999948685e-05\n",
      "[93, 80] loss: 0.005392050585942343, validation loss: 0.005197552230455122, average train time (sec): 4.9735000000339366e-05\n",
      "[93, 120] loss: 0.005054064298747107, validation loss: 0.005161236466418179, average train time (sec): 4.88274999995042e-05\n",
      "[93, 160] loss: 0.004977232060628012, validation loss: 0.005191016669894727, average train time (sec): 4.998499999970818e-05\n",
      "[94, 40] loss: 0.005225425271783024, validation loss: 0.0051658999939220695, average train time (sec): 4.9270000000944944e-05\n",
      "[94, 80] loss: 0.005014766886597499, validation loss: 0.005141108112304278, average train time (sec): 4.7374999999760804e-05\n",
      "[94, 120] loss: 0.005331444443436339, validation loss: 0.0051930673104131, average train time (sec): 7.639250000011089e-05\n",
      "[94, 160] loss: 0.005420866678468883, validation loss: 0.005179029054728881, average train time (sec): 5.1842499999565916e-05\n",
      "[95, 40] loss: 0.005134498671395704, validation loss: 0.005179376776312601, average train time (sec): 5.608750000050122e-05\n",
      "[95, 80] loss: 0.0051743168500252065, validation loss: 0.00517110569613441, average train time (sec): 5.0472499999898446e-05\n",
      "[95, 120] loss: 0.00534461751813069, validation loss: 0.00519800621945903, average train time (sec): 4.197499999918364e-05\n",
      "[95, 160] loss: 0.005126259074313566, validation loss: 0.005338805196103903, average train time (sec): 4.547999999999774e-05\n",
      "[96, 40] loss: 0.005350021604681387, validation loss: 0.0053200679128321835, average train time (sec): 4.4149999999376634e-05\n",
      "[96, 80] loss: 0.005216390447458252, validation loss: 0.005340468656834004, average train time (sec): 4.652500000048576e-05\n",
      "[96, 120] loss: 0.005131677148165181, validation loss: 0.005195329110753143, average train time (sec): 5.0832499999842186e-05\n",
      "[96, 160] loss: 0.005293044477002695, validation loss: 0.005134801340799006, average train time (sec): 5.414000000030228e-05\n",
      "[97, 40] loss: 0.005170085083227605, validation loss: 0.005109933244486181, average train time (sec): 4.628249999996115e-05\n",
      "[97, 80] loss: 0.004864346102112904, validation loss: 0.0051543679492512965, average train time (sec): 4.623250000008738e-05\n",
      "[97, 120] loss: 0.00533967690425925, validation loss: 0.005135926479508854, average train time (sec): 4.971500000010565e-05\n",
      "[97, 160] loss: 0.005138896236894652, validation loss: 0.005146414331459212, average train time (sec): 4.695749999967802e-05\n",
      "[98, 40] loss: 0.005193345859879628, validation loss: 0.005150045118874537, average train time (sec): 4.77224999997361e-05\n",
      "[98, 80] loss: 0.00499838549294509, validation loss: 0.005113645223900676, average train time (sec): 4.6869999999898936e-05\n",
      "[98, 120] loss: 0.005261537397745997, validation loss: 0.005130190200189936, average train time (sec): 6.704500000012103e-05\n",
      "[98, 160] loss: 0.0051460827060509475, validation loss: 0.005181479219452671, average train time (sec): 4.771999999917398e-05\n",
      "[99, 40] loss: 0.00517780571244657, validation loss: 0.0051000028725643205, average train time (sec): 4.878999999959888e-05\n",
      "[99, 80] loss: 0.005162504100007936, validation loss: 0.005115279791665808, average train time (sec): 4.81949999993958e-05\n",
      "[99, 120] loss: 0.005800225946586579, validation loss: 0.005508055963184474, average train time (sec): 4.7612500000582256e-05\n",
      "[99, 160] loss: 0.005834001902258024, validation loss: 0.0059636288919960555, average train time (sec): 4.846250000127839e-05\n",
      "[100, 40] loss: 0.005472173588350416, validation loss: 0.005067124620150283, average train time (sec): 4.771250000032978e-05\n",
      "[100, 80] loss: 0.005377934209536761, validation loss: 0.005292063289023233, average train time (sec): 5.606499999970538e-05\n",
      "[100, 120] loss: 0.005952030664775521, validation loss: 0.005183094611637435, average train time (sec): 4.674749999935557e-05\n",
      "[100, 160] loss: 0.005025306879542768, validation loss: 0.005018919921603124, average train time (sec): 4.3670000000872736e-05\n",
      "[101, 40] loss: 0.004755662335082888, validation loss: 0.005044275903547148, average train time (sec): 4.7127499999533026e-05\n",
      "[101, 80] loss: 0.0053089532069861885, validation loss: 0.005043646636998879, average train time (sec): 5.659250000036309e-05\n",
      "[101, 120] loss: 0.0050390758842695504, validation loss: 0.004996778922296077, average train time (sec): 5.5629999999950995e-05\n",
      "[101, 160] loss: 0.005034708604216576, validation loss: 0.0050309513923975655, average train time (sec): 4.5347500000048056e-05\n",
      "[102, 40] loss: 0.005015663633821532, validation loss: 0.005020439646751532, average train time (sec): 4.5092499999555005e-05\n",
      "[102, 80] loss: 0.004791888420004398, validation loss: 0.005005947208770041, average train time (sec): 4.399000000034903e-05\n",
      "[102, 120] loss: 0.005160263826837763, validation loss: 0.004988129760296839, average train time (sec): 4.272249999957012e-05\n",
      "[102, 160] loss: 0.005049771943595261, validation loss: 0.005014751730311029, average train time (sec): 6.179250000002413e-05\n",
      "[103, 40] loss: 0.00509975262102671, validation loss: 0.005007602902621312, average train time (sec): 4.395750000014686e-05\n",
      "[103, 80] loss: 0.004593296226812526, validation loss: 0.005010592061499099, average train time (sec): 4.9704999999278246e-05\n",
      "[103, 120] loss: 0.0050078428292181345, validation loss: 0.004994158510048434, average train time (sec): 4.3252499999368865e-05\n",
      "[103, 160] loss: 0.005124892015010119, validation loss: 0.004985983628463352, average train time (sec): 4.8967499999719166e-05\n",
      "[104, 40] loss: 0.00490573161514476, validation loss: 0.0049750920877141775, average train time (sec): 4.689250000069478e-05\n",
      "[104, 80] loss: 0.004880739492364228, validation loss: 0.00498211804232648, average train time (sec): 4.533500000007962e-05\n",
      "[104, 120] loss: 0.005017519620014355, validation loss: 0.0050261501653365934, average train time (sec): 6.01150000008488e-05\n",
      "[104, 160] loss: 0.00517711088177748, validation loss: 0.005016423955138, average train time (sec): 4.748249999977361e-05\n",
      "[105, 40] loss: 0.005102561955573038, validation loss: 0.00508817024353259, average train time (sec): 5.654750000019249e-05\n",
      "[105, 80] loss: 0.0049022950930520896, validation loss: 0.0049925992520139465, average train time (sec): 4.594250000025113e-05\n",
      "[105, 120] loss: 0.005105001881020144, validation loss: 0.004998069260937144, average train time (sec): 4.562499999991587e-05\n",
      "[105, 160] loss: 0.005333690089173615, validation loss: 0.005032134795877731, average train time (sec): 4.895749999889176e-05\n",
      "[106, 40] loss: 0.0049260186962783335, validation loss: 0.004973831973126474, average train time (sec): 4.80975000002104e-05\n",
      "[106, 80] loss: 0.0050819477823097255, validation loss: 0.004945518150222751, average train time (sec): 6.007749999952239e-05\n",
      "[106, 120] loss: 0.0050309317244682464, validation loss: 0.005062091726598874, average train time (sec): 4.8119999999585164e-05\n",
      "[106, 160] loss: 0.0050710434967186305, validation loss: 0.005123298334063224, average train time (sec): 5.5612500000279395e-05\n",
      "[107, 40] loss: 0.004835594852920622, validation loss: 0.004999816777922635, average train time (sec): 5.6717500000047495e-05\n",
      "[107, 80] loss: 0.005025292548816651, validation loss: 0.005008867647463702, average train time (sec): 4.8690000001272436e-05\n",
      "[107, 120] loss: 0.004961345106130466, validation loss: 0.004956611172946275, average train time (sec): 4.692500000089694e-05\n",
      "[107, 160] loss: 0.004960682481760159, validation loss: 0.004935917031582234, average train time (sec): 4.7197499999640516e-05\n",
      "[108, 40] loss: 0.004946029838174581, validation loss: 0.004909128152747762, average train time (sec): 5.0557499999115405e-05\n",
      "[108, 80] loss: 0.004914684413233772, validation loss: 0.004910146786813748, average train time (sec): 4.767249999986234e-05\n",
      "[108, 120] loss: 0.004919213487301022, validation loss: 0.004893476666250038, average train time (sec): 4.80699999997114e-05\n",
      "[108, 160] loss: 0.004760311252903193, validation loss: 0.004915958929385217, average train time (sec): 4.8050000000898765e-05\n",
      "[109, 40] loss: 0.004716555768391117, validation loss: 0.004887468796574844, average train time (sec): 5.1779999999723714e-05\n",
      "[109, 80] loss: 0.004731922957580537, validation loss: 0.004897704769699079, average train time (sec): 4.796249999969859e-05\n",
      "[109, 120] loss: 0.004691010975511745, validation loss: 0.004868480820595374, average train time (sec): 4.836000000096874e-05\n",
      "[109, 160] loss: 0.0053045897802803665, validation loss: 0.004894956098518001, average train time (sec): 4.7630000000253855e-05\n",
      "[110, 40] loss: 0.004853948298841715, validation loss: 0.004940617073959899, average train time (sec): 4.7022500000082344e-05\n",
      "[110, 80] loss: 0.004960095201386139, validation loss: 0.0049605894403286135, average train time (sec): 4.5577500000604235e-05\n",
      "[110, 120] loss: 0.005342559743439779, validation loss: 0.004937024295048893, average train time (sec): 4.9222500000212224e-05\n",
      "[110, 160] loss: 0.004765559558290988, validation loss: 0.004903138492186114, average train time (sec): 4.708750000048667e-05\n",
      "[111, 40] loss: 0.004804198443889618, validation loss: 0.004899559898372248, average train time (sec): 4.8085000000241965e-05\n",
      "[111, 80] loss: 0.0048600885842461135, validation loss: 0.004871378178304096, average train time (sec): 4.9052499998936125e-05\n",
      "[111, 120] loss: 0.004778171511134133, validation loss: 0.0049011363199789005, average train time (sec): 4.459750000052054e-05\n",
      "[111, 160] loss: 0.004934899345971644, validation loss: 0.004908757385323351, average train time (sec): 5.554749999987507e-05\n",
      "[112, 40] loss: 0.004672944254707545, validation loss: 0.0048546342240681625, average train time (sec): 4.706249999912871e-05\n",
      "[112, 80] loss: 0.004764409502968192, validation loss: 0.004942993347902062, average train time (sec): 4.34699999999566e-05\n",
      "[112, 120] loss: 0.005088805448031053, validation loss: 0.004932443237916197, average train time (sec): 5.387499999898182e-05\n",
      "[112, 160] loss: 0.005321994866244495, validation loss: 0.004911831158371466, average train time (sec): 4.802750000010292e-05\n",
      "[113, 40] loss: 0.005211758543737233, validation loss: 0.004898021094290153, average train time (sec): 0.00040852999999998476\n",
      "[113, 80] loss: 0.005471621797187254, validation loss: 0.004890372603253092, average train time (sec): 4.6494999999424635e-05\n",
      "[113, 120] loss: 0.004821472120238468, validation loss: 0.0048897483623323015, average train time (sec): 4.596499999962589e-05\n",
      "[113, 160] loss: 0.004746704845456406, validation loss: 0.004908296442151351, average train time (sec): 4.499249999980748e-05\n",
      "[114, 40] loss: 0.004827796493191272, validation loss: 0.0048345996787385, average train time (sec): 4.926750000038283e-05\n",
      "[114, 80] loss: 0.004943023761734366, validation loss: 0.00500702426575546, average train time (sec): 5.448750000027758e-05\n",
      "[114, 120] loss: 0.004848034330643713, validation loss: 0.004939522651322889, average train time (sec): 4.552999999987151e-05\n",
      "[114, 160] loss: 0.00490013561793603, validation loss: 0.0048447528080839035, average train time (sec): 4.629249999936747e-05\n",
      "[115, 40] loss: 0.004684302560053766, validation loss: 0.004788833977830298, average train time (sec): 4.635000000092759e-05\n",
      "[115, 80] loss: 0.004817623650887981, validation loss: 0.004772187175475202, average train time (sec): 5.1917500000797646e-05\n",
      "[115, 120] loss: 0.004559623898239806, validation loss: 0.004787629421905808, average train time (sec): 4.43175000000906e-05\n",
      "[115, 160] loss: 0.004739026649622247, validation loss: 0.004794465645901718, average train time (sec): 9.340000000008785e-05\n",
      "[116, 40] loss: 0.0048447668843436984, validation loss: 0.004796931304845889, average train time (sec): 4.52975000001743e-05\n",
      "[116, 80] loss: 0.004882988182362169, validation loss: 0.004844335940192049, average train time (sec): 4.817000000088001e-05\n",
      "[116, 120] loss: 0.004697081027552485, validation loss: 0.0047542479609684, average train time (sec): 4.7220000000436356e-05\n",
      "[116, 160] loss: 0.004847009747754783, validation loss: 0.004800011711370833, average train time (sec): 4.7382500000026084e-05\n",
      "[117, 40] loss: 0.004585684364428744, validation loss: 0.004759926704760149, average train time (sec): 4.5987500000421734e-05\n",
      "[117, 80] loss: 0.004760262893978506, validation loss: 0.004736094102966336, average train time (sec): 4.800250000016604e-05\n",
      "[117, 120] loss: 0.0047852962161414325, validation loss: 0.00474053759233288, average train time (sec): 5.177500000002056e-05\n",
      "[117, 160] loss: 0.0047693885222543034, validation loss: 0.004739681052325188, average train time (sec): 5.193000000076608e-05\n",
      "[118, 40] loss: 0.004638425423763692, validation loss: 0.00476926152664676, average train time (sec): 4.9237500000742784e-05\n",
      "[118, 80] loss: 0.004834921105066314, validation loss: 0.004764526770538035, average train time (sec): 4.69199999997727e-05\n",
      "[118, 120] loss: 0.004906911455327645, validation loss: 0.004837184538186158, average train time (sec): 5.349500000022545e-05\n",
      "[118, 160] loss: 0.0048938531777821485, validation loss: 0.004908294860660186, average train time (sec): 4.761999999942645e-05\n",
      "[119, 40] loss: 0.005097324989037588, validation loss: 0.004983073170736151, average train time (sec): 5.616250000031187e-05\n",
      "[119, 80] loss: 0.004913688619853929, validation loss: 0.004801566391867006, average train time (sec): 4.919250000057218e-05\n",
      "[119, 120] loss: 0.005194256355753169, validation loss: 0.0049003494534430635, average train time (sec): 4.644249999898875e-05\n",
      "[119, 160] loss: 0.005010954127646983, validation loss: 0.004963859937698493, average train time (sec): 5.2455000000861675e-05\n",
      "Saved checkpoint for epoch 119: PC_ConvMF_r12_cdim2-c00f\n",
      "[120, 40] loss: 0.004930452647386119, validation loss: 0.0049323240418057395, average train time (sec): 4.5269999999675294e-05\n",
      "[120, 80] loss: 0.004802559415111318, validation loss: 0.0047841134815002385, average train time (sec): 5.5152500000588137e-05\n",
      "[120, 120] loss: 0.004898069961927831, validation loss: 0.004797262899612762, average train time (sec): 4.605499999996709e-05\n",
      "[120, 160] loss: 0.005684720014687628, validation loss: 0.005049195799554857, average train time (sec): 4.49674999998706e-05\n",
      "[121, 40] loss: 0.005316688399761915, validation loss: 0.004878135639646987, average train time (sec): 4.570500000085076e-05\n",
      "[121, 80] loss: 0.0047466333664488046, validation loss: 0.004761597449135668, average train time (sec): 4.7007499999551784e-05\n",
      "[121, 120] loss: 0.004423972079530358, validation loss: 0.004745637444462979, average train time (sec): 4.722749999928055e-05\n",
      "[121, 160] loss: 0.004657371033681556, validation loss: 0.004664362561976853, average train time (sec): 4.6509999999955196e-05\n",
      "[122, 40] loss: 0.004609488969435915, validation loss: 0.0046903365862749095, average train time (sec): 4.61725000008073e-05\n",
      "[122, 80] loss: 0.004475015087518841, validation loss: 0.004716373360627946, average train time (sec): 4.531750000040802e-05\n",
      "[122, 120] loss: 0.004597788443788886, validation loss: 0.004734230530887561, average train time (sec): 4.308500000007598e-05\n",
      "[122, 160] loss: 0.0048959915526211265, validation loss: 0.0046988482991198325, average train time (sec): 5.6322500000760556e-05\n",
      "[123, 40] loss: 0.004736986133502796, validation loss: 0.004673202952616058, average train time (sec): 4.847249999926362e-05\n",
      "[123, 80] loss: 0.0048070177144836634, validation loss: 0.004705218866221466, average train time (sec): 4.62599999991653e-05\n",
      "[123, 120] loss: 0.004594311688560992, validation loss: 0.004682941182147501, average train time (sec): 4.669249999977865e-05\n",
      "[123, 160] loss: 0.0044938076636753975, validation loss: 0.004697431493901981, average train time (sec): 4.637750000000551e-05\n",
      "[124, 40] loss: 0.004638598946621641, validation loss: 0.004699868668433068, average train time (sec): 5.0077500000611507e-05\n",
      "[124, 80] loss: 0.004530076269293204, validation loss: 0.004730257693291554, average train time (sec): 4.818000000028633e-05\n",
      "[124, 120] loss: 0.004739807167788967, validation loss: 0.004685590030484885, average train time (sec): 4.7100000000455114e-05\n",
      "[124, 160] loss: 0.004727269150316715, validation loss: 0.0046680777175527694, average train time (sec): 4.39249999999447e-05\n",
      "[125, 40] loss: 0.004267931240610779, validation loss: 0.00471036990594892, average train time (sec): 4.818999999969265e-05\n",
      "[125, 80] loss: 0.004715876432601363, validation loss: 0.004730696680094555, average train time (sec): 4.844249999962358e-05\n",
      "[125, 120] loss: 0.004741805198136717, validation loss: 0.0046588200197186114, average train time (sec): 5.7502500000339295e-05\n",
      "[125, 160] loss: 0.004797296784818173, validation loss: 0.004683382101884147, average train time (sec): 4.6757500000182973e-05\n",
      "[126, 40] loss: 0.004244889732217416, validation loss: 0.004706116977481628, average train time (sec): 4.569750000058548e-05\n",
      "[126, 80] loss: 0.0044482725148554895, validation loss: 0.0047035703813340865, average train time (sec): 4.614750000087042e-05\n",
      "[126, 120] loss: 0.004901950672501698, validation loss: 0.004693689378294742, average train time (sec): 4.652249999992364e-05\n",
      "[126, 160] loss: 0.004878059262409806, validation loss: 0.004631436311305975, average train time (sec): 4.228000000097154e-05\n",
      "[127, 40] loss: 0.004799761017784477, validation loss: 0.004634660519308077, average train time (sec): 4.569500000002335e-05\n",
      "[127, 80] loss: 0.004554962634574622, validation loss: 0.004689447247897679, average train time (sec): 4.2960000000391575e-05\n",
      "[127, 120] loss: 0.004857122036628425, validation loss: 0.004924128983029217, average train time (sec): 4.797249999910491e-05\n",
      "[127, 160] loss: 0.004639234632486477, validation loss: 0.004724578861639185, average train time (sec): 4.482749999965563e-05\n",
      "[128, 40] loss: 0.004721425240859389, validation loss: 0.004601551268144317, average train time (sec): 4.282999999958292e-05\n",
      "[128, 80] loss: 0.004357489908579737, validation loss: 0.004608779021029202, average train time (sec): 4.380249999940134e-05\n",
      "[128, 120] loss: 0.004631349327974021, validation loss: 0.004667080218358984, average train time (sec): 4.6067499999935536e-05\n",
      "[128, 160] loss: 0.004779145587235689, validation loss: 0.004632319741056494, average train time (sec): 4.442999999980657e-05\n",
      "[129, 40] loss: 0.004600884177489206, validation loss: 0.004633155581102056, average train time (sec): 5.9377499999868634e-05\n",
      "[129, 80] loss: 0.0047464091447182, validation loss: 0.004735201961835319, average train time (sec): 4.2977500000063175e-05\n",
      "[129, 120] loss: 0.004702981881564483, validation loss: 0.00469551885605983, average train time (sec): 5.147999999906005e-05\n",
      "[129, 160] loss: 0.004696346336277202, validation loss: 0.004619979036023032, average train time (sec): 5.154499999946438e-05\n",
      "[130, 40] loss: 0.004563697800040245, validation loss: 0.004651313788204823, average train time (sec): 5.315750000107755e-05\n",
      "[130, 80] loss: 0.004543270531576127, validation loss: 0.004638012085672257, average train time (sec): 5.540750000108119e-05\n",
      "[130, 120] loss: 0.0045961554511450235, validation loss: 0.004652797090733108, average train time (sec): 4.7267499999748e-05\n",
      "[130, 160] loss: 0.004776009672787041, validation loss: 0.004588760672804882, average train time (sec): 5.416499999881808e-05\n",
      "[131, 40] loss: 0.004756904015084729, validation loss: 0.004626386179500875, average train time (sec): 4.689250000069478e-05\n",
      "[131, 80] loss: 0.004478296957677231, validation loss: 0.004606709991283012, average train time (sec): 4.5307499999580617e-05\n",
      "[131, 120] loss: 0.00450159625033848, validation loss: 0.004619421678999404, average train time (sec): 4.3604999999047325e-05\n",
      "[131, 160] loss: 0.004458018019795418, validation loss: 0.004595519148937936, average train time (sec): 4.481250000054615e-05\n",
      "[132, 40] loss: 0.004418838577112183, validation loss: 0.004744756958043238, average train time (sec): 4.2764999999178596e-05\n",
      "[132, 80] loss: 0.004666220443323254, validation loss: 0.004615723133473745, average train time (sec): 4.824499999926957e-05\n",
      "[132, 120] loss: 0.004835492349229753, validation loss: 0.0046717029082465845, average train time (sec): 5.049250000013217e-05\n",
      "[132, 160] loss: 0.004362869693432003, validation loss: 0.00458635914332743, average train time (sec): 4.9344999999334506e-05\n",
      "[133, 40] loss: 0.00433412793208845, validation loss: 0.004573123204469119, average train time (sec): 5.5494999999439186e-05\n",
      "[133, 80] loss: 0.00453273524180986, validation loss: 0.004567216088960193, average train time (sec): 5.1442499999154737e-05\n",
      "[133, 120] loss: 0.004688068048562854, validation loss: 0.004586981468886699, average train time (sec): 4.71450000020468e-05\n",
      "[133, 160] loss: 0.004670920653734356, validation loss: 0.004573552368454776, average train time (sec): 5.03524999999172e-05\n",
      "[134, 40] loss: 0.004639309225603938, validation loss: 0.004600250711313115, average train time (sec): 5.045999999993e-05\n",
      "[134, 80] loss: 0.0045512538403272625, validation loss: 0.004584712428831548, average train time (sec): 5.4877499999861355e-05\n",
      "[134, 120] loss: 0.004511410108534619, validation loss: 0.004599761389160775, average train time (sec): 4.849500000148055e-05\n",
      "[134, 160] loss: 0.004547141469083726, validation loss: 0.004620737839876762, average train time (sec): 4.943499999967571e-05\n",
      "[135, 40] loss: 0.004565319191897288, validation loss: 0.004609408942139092, average train time (sec): 4.545750000204407e-05\n",
      "[135, 80] loss: 0.004870055435458198, validation loss: 0.004599027181887683, average train time (sec): 4.699750000156655e-05\n",
      "[135, 120] loss: 0.0045944211597088724, validation loss: 0.004600531250273563, average train time (sec): 4.470249999997122e-05\n",
      "[135, 160] loss: 0.004563141718972474, validation loss: 0.00453685589117121, average train time (sec): 4.5792500000629846e-05\n",
      "[136, 40] loss: 0.004872043844079599, validation loss: 0.004563931173662532, average train time (sec): 4.8792500001582086e-05\n",
      "[136, 80] loss: 0.0045440105197485535, validation loss: 0.0047818440416792654, average train time (sec): 9.194749999892337e-05\n",
      "[136, 120] loss: 0.004828714171890169, validation loss: 0.004584213832990741, average train time (sec): 4.3714999998201164e-05\n",
      "[136, 160] loss: 0.004365970002254471, validation loss: 0.004565758617454261, average train time (sec): 4.8560000001884875e-05\n",
      "[137, 40] loss: 0.00445917954784818, validation loss: 0.004549400349376055, average train time (sec): 4.92024999999785e-05\n",
      "[137, 80] loss: 0.004286682413658127, validation loss: 0.004526264310972589, average train time (sec): 4.5192499999302524e-05\n",
      "[137, 120] loss: 0.00444836167152971, validation loss: 0.004495066190841344, average train time (sec): 4.700249999984862e-05\n",
      "[137, 160] loss: 0.004756211186759174, validation loss: 0.004507028251745791, average train time (sec): 4.7589999999786416e-05\n",
      "[138, 40] loss: 0.0043721938971430065, validation loss: 0.004535203263655586, average train time (sec): 9.754249999787135e-05\n",
      "[138, 80] loss: 0.00449813422455918, validation loss: 0.004486991228746637, average train time (sec): 4.600750000065546e-05\n",
      "[138, 120] loss: 0.0045844777952879666, validation loss: 0.004791528105138327, average train time (sec): 4.6604999999999565e-05\n",
      "[138, 160] loss: 0.0045782032771967355, validation loss: 0.004620722486233374, average train time (sec): 4.896250000001601e-05\n",
      "[139, 40] loss: 0.004262229654705152, validation loss: 0.004476350617928887, average train time (sec): 4.687250000188214e-05\n",
      "[139, 80] loss: 0.00498951852787286, validation loss: 0.004569304100993388, average train time (sec): 5.120250000061333e-05\n",
      "[139, 120] loss: 0.004398778104223311, validation loss: 0.004498676388120314, average train time (sec): 4.5610000000806394e-05\n",
      "[139, 160] loss: 0.004642945277737454, validation loss: 0.004745574944810766, average train time (sec): 4.423249999945256e-05\n",
      "[140, 40] loss: 0.004964360018493608, validation loss: 0.004764823853653276, average train time (sec): 4.517750000161413e-05\n",
      "[140, 80] loss: 0.004593100515194237, validation loss: 0.004570756054852369, average train time (sec): 4.542500000184191e-05\n",
      "[140, 120] loss: 0.005206902627833188, validation loss: 0.0054870300732974735, average train time (sec): 5.4142499999443315e-05\n",
      "[140, 160] loss: 0.004908526735380292, validation loss: 0.004633516477385782, average train time (sec): 4.604249999999866e-05\n",
      "[141, 40] loss: 0.004506444721482694, validation loss: 0.004515099690629626, average train time (sec): 4.626749999943058e-05\n",
      "[141, 80] loss: 0.004301759513327852, validation loss: 0.004695698421202459, average train time (sec): 4.104250000125376e-05\n",
      "[141, 120] loss: 0.004658215440576896, validation loss: 0.00452584407801898, average train time (sec): 4.558249999888631e-05\n",
      "[141, 160] loss: 0.005073641217313707, validation loss: 0.005052915009898397, average train time (sec): 4.7892500001012193e-05\n",
      "[142, 40] loss: 0.004844292689813301, validation loss: 0.004761672684184785, average train time (sec): 4.7094999999330867e-05\n",
      "[142, 80] loss: 0.004598470259224996, validation loss: 0.004666613744360939, average train time (sec): 4.7842500001138434e-05\n",
      "[142, 120] loss: 0.004778887995053082, validation loss: 0.004599928583528074, average train time (sec): 4.750249999858624e-05\n",
      "[142, 160] loss: 0.005119822727283463, validation loss: 0.004539755621116678, average train time (sec): 5.1357500001358855e-05\n",
      "[143, 40] loss: 0.004547165113035589, validation loss: 0.0044918431030621505, average train time (sec): 5.398250000041571e-05\n",
      "[143, 80] loss: 0.004391523753292858, validation loss: 0.004489302059705809, average train time (sec): 4.787000000021635e-05\n",
      "[143, 120] loss: 0.004492981574730948, validation loss: 0.004450210954396511, average train time (sec): 5.3345000000604156e-05\n",
      "[143, 160] loss: 0.004396123206242919, validation loss: 0.0044573174156951455, average train time (sec): 4.687250000188214e-05\n",
      "[144, 40] loss: 0.004215697885956615, validation loss: 0.004478113141508316, average train time (sec): 8.19575000008399e-05\n",
      "[144, 80] loss: 0.0043319121876265855, validation loss: 0.004447745616143604, average train time (sec): 4.547249999973246e-05\n",
      "[144, 120] loss: 0.004613321804208681, validation loss: 0.004454751244201412, average train time (sec): 4.672499999855972e-05\n",
      "[144, 160] loss: 0.004346136894309893, validation loss: 0.0044541751113632375, average train time (sec): 4.67849999978398e-05\n",
      "[145, 40] loss: 0.0041545911983121185, validation loss: 0.004419861374563485, average train time (sec): 4.670749999888812e-05\n",
      "[145, 80] loss: 0.004533445229753852, validation loss: 0.004445559929458881, average train time (sec): 4.9377499999536666e-05\n",
      "[145, 120] loss: 0.004603359272005036, validation loss: 0.004459962134583379, average train time (sec): 5.186750000234497e-05\n",
      "[145, 160] loss: 0.004331294150324539, validation loss: 0.004456980184669483, average train time (sec): 4.546250000032614e-05\n",
      "[146, 40] loss: 0.004313278483459726, validation loss: 0.004456743619949469, average train time (sec): 4.7632499999394895e-05\n",
      "[146, 80] loss: 0.004052173317177221, validation loss: 0.0044362671093417785, average train time (sec): 4.394750000074055e-05\n",
      "[146, 120] loss: 0.004754935659002512, validation loss: 0.004428870352160818, average train time (sec): 4.152999999860185e-05\n",
      "[146, 160] loss: 0.004487615230027586, validation loss: 0.0044322155222718445, average train time (sec): 4.2882500000018806e-05\n",
      "[147, 40] loss: 0.004375167924445122, validation loss: 0.0044069520399888165, average train time (sec): 4.290000000253258e-05\n",
      "[147, 80] loss: 0.004340747720561922, validation loss: 0.004451085123637656, average train time (sec): 4.4449999998619204e-05\n",
      "[147, 120] loss: 0.00434987444896251, validation loss: 0.004453553712733512, average train time (sec): 4.308000000037282e-05\n",
      "[147, 160] loss: 0.0041332687484100464, validation loss: 0.004453229968313058, average train time (sec): 5.34899999991012e-05\n",
      "[148, 40] loss: 0.004302837967406959, validation loss: 0.004443043144419789, average train time (sec): 6.11199999980272e-05\n",
      "[148, 80] loss: 0.0047146558703389015, validation loss: 0.0047683097193685344, average train time (sec): 4.394999999988158e-05\n",
      "[148, 120] loss: 0.004474511265289039, validation loss: 0.0045488634419117895, average train time (sec): 4.815499999892836e-05\n",
      "[148, 160] loss: 0.0045097868307493625, validation loss: 0.004476275800217716, average train time (sec): 4.997249999973974e-05\n",
      "[149, 40] loss: 0.004487859120126813, validation loss: 0.004470935429639692, average train time (sec): 4.979249999905733e-05\n",
      "[149, 80] loss: 0.004195913078729063, validation loss: 0.004386370522760839, average train time (sec): 6.115500000021256e-05\n",
      "[149, 120] loss: 0.004594217473641038, validation loss: 0.0044096992614696615, average train time (sec): 4.5107500000085565e-05\n",
      "[149, 160] loss: 0.004506414767820388, validation loss: 0.0044172220898546135, average train time (sec): 5.174750000094264e-05\n",
      "[150, 40] loss: 0.00443108276813291, validation loss: 0.004395194733866824, average train time (sec): 4.797999999937019e-05\n",
      "[150, 80] loss: 0.004576549958437681, validation loss: 0.004414816013590063, average train time (sec): 4.850500000088687e-05\n",
      "[150, 120] loss: 0.004340002703247592, validation loss: 0.004426013287332542, average train time (sec): 4.7115000000985674e-05\n",
      "[150, 160] loss: 0.004264504660386592, validation loss: 0.004433231076823091, average train time (sec): 4.5912499999190004e-05\n",
      "[151, 40] loss: 0.004508096148492768, validation loss: 0.004457628767375114, average train time (sec): 4.618499999935466e-05\n",
      "[151, 80] loss: 0.004514651937643066, validation loss: 0.00439680970432061, average train time (sec): 5.0102500000548386e-05\n",
      "[151, 120] loss: 0.004292223497759551, validation loss: 0.0044365481403217, average train time (sec): 5.050750000066273e-05\n",
      "[151, 160] loss: 0.004160839621908963, validation loss: 0.004468986320854077, average train time (sec): 4.8567499999307986e-05\n",
      "[152, 40] loss: 0.0043349249812308695, validation loss: 0.004446669916604769, average train time (sec): 4.5324999999252216e-05\n",
      "[152, 80] loss: 0.004425346507923677, validation loss: 0.00441339576862893, average train time (sec): 4.734249999955864e-05\n",
      "[152, 120] loss: 0.004449817433487624, validation loss: 0.004409285908002617, average train time (sec): 4.558249999888631e-05\n",
      "[152, 160] loss: 0.004280838865088299, validation loss: 0.0044282504427686055, average train time (sec): 4.418750000070304e-05\n",
      "[153, 40] loss: 0.004491250327555462, validation loss: 0.004434675132012311, average train time (sec): 4.879249999873991e-05\n",
      "[153, 80] loss: 0.004461570963030681, validation loss: 0.0044016345131720576, average train time (sec): 5.431250000071941e-05\n",
      "[153, 120] loss: 0.004136668128194287, validation loss: 0.0043752358057799765, average train time (sec): 5.752749999885509e-05\n",
      "[153, 160] loss: 0.004461202508537099, validation loss: 0.004334041172251949, average train time (sec): 5.2132499999402174e-05\n",
      "[154, 40] loss: 0.004204779997235164, validation loss: 0.004380649228070704, average train time (sec): 4.229250000093998e-05\n",
      "[154, 80] loss: 0.004681343532865867, validation loss: 0.00435515407490421, average train time (sec): 4.270750000046064e-05\n",
      "[154, 120] loss: 0.003958096983842552, validation loss: 0.00436644574170405, average train time (sec): 7.161249999967367e-05\n",
      "[154, 160] loss: 0.004286009591305628, validation loss: 0.004386197924965395, average train time (sec): 4.698000000189495e-05\n",
      "[155, 40] loss: 0.004314401501324028, validation loss: 0.004413723497528513, average train time (sec): 4.9322500001380834e-05\n",
      "[155, 80] loss: 0.004339349153451621, validation loss: 0.004349139655219778, average train time (sec): 4.839750000087406e-05\n",
      "[155, 120] loss: 0.004324672248912975, validation loss: 0.004414005459831009, average train time (sec): 4.607250000105978e-05\n",
      "[155, 160] loss: 0.0045131304010283205, validation loss: 0.004397067698245903, average train time (sec): 4.630249999877378e-05\n",
      "[156, 40] loss: 0.004374844551784917, validation loss: 0.00438887311391673, average train time (sec): 4.477500000064083e-05\n",
      "[156, 80] loss: 0.0042176582908723505, validation loss: 0.004382422971451339, average train time (sec): 4.7139999998080385e-05\n",
      "[156, 120] loss: 0.0044962306914385405, validation loss: 0.0044983314780764425, average train time (sec): 4.735999999923024e-05\n",
      "[156, 160] loss: 0.004629576957086101, validation loss: 0.00475309026989875, average train time (sec): 4.630999999903907e-05\n",
      "[157, 40] loss: 0.004685905884252861, validation loss: 0.004552183057761418, average train time (sec): 5.188250000003336e-05\n",
      "[157, 80] loss: 0.0050313645275309685, validation loss: 0.004469383723225515, average train time (sec): 5.255750000117132e-05\n",
      "[157, 120] loss: 0.004233484447468072, validation loss: 0.004431457320263363, average train time (sec): 4.880500000012944e-05\n",
      "[157, 160] loss: 0.004632486577611417, validation loss: 0.004443865761442005, average train time (sec): 4.656499999953212e-05\n",
      "[158, 40] loss: 0.0042954865552019324, validation loss: 0.004339728649389351, average train time (sec): 4.569500000002335e-05\n",
      "[158, 80] loss: 0.00436403242056258, validation loss: 0.004338970574778768, average train time (sec): 5.0537500001723856e-05\n",
      "[158, 120] loss: 0.004315505444537848, validation loss: 0.004318101603959529, average train time (sec): 5.498499999987416e-05\n",
      "[158, 160] loss: 0.004485479375580326, validation loss: 0.004354315260776652, average train time (sec): 5.675250000081178e-05\n",
      "[159, 40] loss: 0.004221530596259982, validation loss: 0.0042906989044738265, average train time (sec): 4.769749999979922e-05\n",
      "[159, 80] loss: 0.004032196127809584, validation loss: 0.004365317092962422, average train time (sec): 4.697500000077071e-05\n",
      "[159, 120] loss: 0.004506351827876643, validation loss: 0.004342053766485374, average train time (sec): 5.2707499997950434e-05\n",
      "[159, 160] loss: 0.004406870895763859, validation loss: 0.00436488803880254, average train time (sec): 4.969999999957508e-05\n",
      "Saved checkpoint for epoch 159: PC_ConvMF_r12_cdim2-c00f\n",
      "[160, 40] loss: 0.004343240975867957, validation loss: 0.00433958422849482, average train time (sec): 4.660999999828164e-05\n",
      "[160, 80] loss: 0.004308323311852292, validation loss: 0.004376364419377356, average train time (sec): 5.7812500000409275e-05\n",
      "[160, 120] loss: 0.004586875147651881, validation loss: 0.004336678813967221, average train time (sec): 4.675000000133878e-05\n",
      "[160, 160] loss: 0.0041282344667706635, validation loss: 0.004275700160882102, average train time (sec): 5.029250000063712e-05\n",
      "[161, 40] loss: 0.0043858831049874425, validation loss: 0.004343103766792787, average train time (sec): 4.9172499998917374e-05\n",
      "[161, 80] loss: 0.004265256063081324, validation loss: 0.004318014283682096, average train time (sec): 4.6159999999417775e-05\n",
      "[161, 120] loss: 0.00438911541714333, validation loss: 0.004331803678552497, average train time (sec): 5.226499999935186e-05\n",
      "[161, 160] loss: 0.004182657133787871, validation loss: 0.004284675782194959, average train time (sec): 4.674500000021453e-05\n",
      "[162, 40] loss: 0.0043016448442358525, validation loss: 0.004368249379660723, average train time (sec): 4.6827500000290456e-05\n",
      "[162, 80] loss: 0.004367455933243036, validation loss: 0.004362627099496576, average train time (sec): 4.653000000018892e-05\n",
      "[162, 120] loss: 0.0042821563023608174, validation loss: 0.004387095785822789, average train time (sec): 4.555499999980839e-05\n",
      "[162, 160] loss: 0.004147571168141439, validation loss: 0.004400332383635752, average train time (sec): 4.780250000067099e-05\n",
      "[163, 40] loss: 0.004434019525069744, validation loss: 0.004372463240903223, average train time (sec): 4.7564999999849536e-05\n",
      "[163, 80] loss: 0.004328093532240018, validation loss: 0.004339996193764063, average train time (sec): 4.7832499998889946e-05\n",
      "[163, 120] loss: 0.0043153783888556065, validation loss: 0.00438518805938931, average train time (sec): 4.5860000000175205e-05\n",
      "[163, 160] loss: 0.0042156692186836155, validation loss: 0.004300869026063186, average train time (sec): 5.102000000078988e-05\n",
      "[164, 40] loss: 0.0043841528473421935, validation loss: 0.004378330190929602, average train time (sec): 4.6189999997636734e-05\n",
      "[164, 80] loss: 0.0047549071023240685, validation loss: 0.004995753650360231, average train time (sec): 4.2134999998211245e-05\n",
      "[164, 120] loss: 0.004711093130754307, validation loss: 0.0046432740582188345, average train time (sec): 4.699499999958334e-05\n",
      "[164, 160] loss: 0.004500315524637699, validation loss: 0.0043254359229907115, average train time (sec): 4.65200000007826e-05\n",
      "[165, 40] loss: 0.00424333456903696, validation loss: 0.004369847291975089, average train time (sec): 4.4900000000325234e-05\n",
      "[165, 80] loss: 0.0045765779505018145, validation loss: 0.004373359164433941, average train time (sec): 4.921000000024378e-05\n",
      "[165, 120] loss: 0.004238350782543421, validation loss: 0.00431994997175797, average train time (sec): 4.560749999882319e-05\n",
      "[165, 160] loss: 0.0043738556210882965, validation loss: 0.004291451162711348, average train time (sec): 4.705000000058135e-05\n",
      "[166, 40] loss: 0.004293050628621131, validation loss: 0.00429132159465467, average train time (sec): 4.956249999850115e-05\n",
      "[166, 80] loss: 0.003988031606422737, validation loss: 0.004297643579226339, average train time (sec): 4.8382500000343495e-05\n",
      "[166, 120] loss: 0.004600921913515776, validation loss: 0.004270891593066308, average train time (sec): 5.0095000000283106e-05\n",
      "[166, 160] loss: 0.0041313462657853964, validation loss: 0.004283382886809841, average train time (sec): 5.6089999998221177e-05\n",
      "[167, 40] loss: 0.0039783189888112245, validation loss: 0.004276691588907028, average train time (sec): 4.922749999991538e-05\n",
      "[167, 80] loss: 0.00424240185529925, validation loss: 0.0042727464317994296, average train time (sec): 4.973750000090149e-05\n",
      "[167, 120] loss: 0.004393226245883852, validation loss: 0.00430614226673431, average train time (sec): 4.644750000011299e-05\n",
      "[167, 160] loss: 0.004276088252663612, validation loss: 0.004287734104953003, average train time (sec): 4.461250000247219e-05\n",
      "[168, 40] loss: 0.004116556933149695, validation loss: 0.004265400137365708, average train time (sec): 5.068750000134514e-05\n",
      "[168, 80] loss: 0.003965647896984592, validation loss: 0.004298009755933341, average train time (sec): 4.803999999865027e-05\n",
      "[168, 120] loss: 0.004320941719925031, validation loss: 0.004335912089478576, average train time (sec): 4.725500000120064e-05\n",
      "[168, 160] loss: 0.0045266399451065805, validation loss: 0.00427224517817486, average train time (sec): 5.011000000081367e-05\n",
      "[169, 40] loss: 0.004449669871246442, validation loss: 0.00434463371013133, average train time (sec): 4.760250000117594e-05\n",
      "[169, 80] loss: 0.0043531962961424146, validation loss: 0.004402319900691509, average train time (sec): 4.225250000047254e-05\n",
      "[169, 120] loss: 0.004149357724236325, validation loss: 0.004313621582147086, average train time (sec): 4.7567500001832744e-05\n",
      "[169, 160] loss: 0.004084814537782222, validation loss: 0.004281632395742356, average train time (sec): 5.168750000166256e-05\n",
      "[170, 40] loss: 0.004223218682454899, validation loss: 0.004276466336241871, average train time (sec): 4.526749999911317e-05\n",
      "[170, 80] loss: 0.004280117654707283, validation loss: 0.004250078984834957, average train time (sec): 5.123500000081549e-05\n",
      "[170, 120] loss: 0.004264639056054875, validation loss: 0.004402692117816153, average train time (sec): 4.605500000138818e-05\n",
      "[170, 160] loss: 0.004152201220858842, validation loss: 0.004269861194463271, average train time (sec): 4.648250000229837e-05\n",
      "[171, 40] loss: 0.004315077018691227, validation loss: 0.004235334457161854, average train time (sec): 4.915750000122898e-05\n",
      "[171, 80] loss: 0.004171097348444164, validation loss: 0.004262935080266786, average train time (sec): 4.4850000000451475e-05\n",
      "[171, 120] loss: 0.004246372275520116, validation loss: 0.004290537052032239, average train time (sec): 4.8584999998979586e-05\n",
      "[171, 160] loss: 0.004093209170969203, validation loss: 0.004272342879184574, average train time (sec): 5.275750000066637e-05\n",
      "[172, 40] loss: 0.004315900907386094, validation loss: 0.00431123522619875, average train time (sec): 4.853499999910582e-05\n",
      "[172, 80] loss: 0.0039016470254864544, validation loss: 0.004254688188117349, average train time (sec): 4.683249999857253e-05\n",
      "[172, 120] loss: 0.004260134242940694, validation loss: 0.004239743399732518, average train time (sec): 4.5469999997749254e-05\n",
      "[172, 160] loss: 0.00435854812967591, validation loss: 0.004266760500921112, average train time (sec): 4.523499999891101e-05\n",
      "[173, 40] loss: 0.0041514896380249414, validation loss: 0.004290581140491479, average train time (sec): 4.724000000067008e-05\n",
      "[173, 80] loss: 0.004067730263341218, validation loss: 0.004232987027861319, average train time (sec): 4.778999999928146e-05\n",
      "[173, 120] loss: 0.00448804561747238, validation loss: 0.004271551435110423, average train time (sec): 5.1644999999211905e-05\n",
      "[173, 160] loss: 0.004391837929142639, validation loss: 0.004391698966259664, average train time (sec): 4.7362500001213445e-05\n",
      "[174, 40] loss: 0.004306843981612474, validation loss: 0.004332056545810598, average train time (sec): 4.70074999981307e-05\n",
      "[174, 80] loss: 0.004154979140730574, validation loss: 0.004287673788637204, average train time (sec): 4.80175000006966e-05\n",
      "[174, 120] loss: 0.0042475111433304845, validation loss: 0.004294870438862522, average train time (sec): 4.675499999962085e-05\n",
      "[174, 160] loss: 0.0045758322812616825, validation loss: 0.004355372320684903, average train time (sec): 4.895250000060969e-05\n",
      "[175, 40] loss: 0.008263835514662787, validation loss: 0.0073792120213356785, average train time (sec): 4.3407499998693313e-05\n",
      "[175, 80] loss: 0.013132198713719845, validation loss: 0.010551987628821494, average train time (sec): 4.469000000142387e-05\n",
      "[175, 120] loss: 0.008468920446466655, validation loss: 0.00546215421449885, average train time (sec): 4.3714999998201164e-05\n",
      "[175, 160] loss: 0.004914386861491949, validation loss: 0.0047726087526963005, average train time (sec): 5.3350000001728404e-05\n",
      "[176, 40] loss: 0.004847518127644434, validation loss: 0.004555702903571556, average train time (sec): 5.445500000007541e-05\n",
      "[176, 80] loss: 0.004619630565866828, validation loss: 0.004538835303084749, average train time (sec): 4.922749999991538e-05\n",
      "[176, 120] loss: 0.004364645015448332, validation loss: 0.004487394118013809, average train time (sec): 5.0070000000346226e-05\n",
      "[176, 160] loss: 0.004332240344956518, validation loss: 0.0044628132512476645, average train time (sec): 4.899749999935921e-05\n",
      "[177, 40] loss: 0.0041837339289486405, validation loss: 0.004401070834576803, average train time (sec): 4.842250000081094e-05\n",
      "[177, 80] loss: 0.004354556312318891, validation loss: 0.004383797291666269, average train time (sec): 4.971250000096461e-05\n",
      "[177, 120] loss: 0.004098684334894642, validation loss: 0.004400685741478261, average train time (sec): 4.897500000140553e-05\n",
      "[177, 160] loss: 0.0045255791861563924, validation loss: 0.004371073268318795, average train time (sec): 5.003750000014407e-05\n",
      "[178, 40] loss: 0.004196023906115442, validation loss: 0.004359004918029005, average train time (sec): 5.8884999998554124e-05\n",
      "[178, 80] loss: 0.004245645797345788, validation loss: 0.004338044106503422, average train time (sec): 4.419750000010936e-05\n",
      "[178, 120] loss: 0.004428322671446949, validation loss: 0.0043446038594856014, average train time (sec): 4.75100000016937e-05\n",
      "[178, 160] loss: 0.004245296871522442, validation loss: 0.004306996570689217, average train time (sec): 5.303249999997206e-05\n",
      "[179, 40] loss: 0.004338526865467429, validation loss: 0.00428608004530927, average train time (sec): 4.6352499998647546e-05\n",
      "[179, 80] loss: 0.004268407740164548, validation loss: 0.004333403541372632, average train time (sec): 4.992500000184918e-05\n",
      "[179, 120] loss: 0.004190906503936276, validation loss: 0.00430358313726929, average train time (sec): 4.6060000002512425e-05\n",
      "[179, 160] loss: 0.004144549235934392, validation loss: 0.004280936148650241, average train time (sec): 5.002750000073775e-05\n",
      "[180, 40] loss: 0.004229090380249545, validation loss: 0.00430134139550885, average train time (sec): 4.475249999984499e-05\n",
      "[180, 80] loss: 0.004235051455907524, validation loss: 0.004278142325896418, average train time (sec): 5.2395000000160505e-05\n",
      "[180, 120] loss: 0.004132549307541922, validation loss: 0.00426744374464143, average train time (sec): 4.54050000001871e-05\n",
      "[180, 160] loss: 0.004234278545482084, validation loss: 0.004279213531364528, average train time (sec): 4.446750000113298e-05\n",
      "[181, 40] loss: 0.004141388967400417, validation loss: 0.004287397748140513, average train time (sec): 4.415999999878295e-05\n",
      "[181, 80] loss: 0.004145073256222531, validation loss: 0.004274582182812803, average train time (sec): 4.572250000194345e-05\n",
      "[181, 120] loss: 0.004534602648345753, validation loss: 0.004268776322275681, average train time (sec): 4.717749999940679e-05\n",
      "[181, 160] loss: 0.004314608499407768, validation loss: 0.004268967669527486, average train time (sec): 5.170249999935095e-05\n",
      "[182, 40] loss: 0.0041052949498407544, validation loss: 0.004281309095018034, average train time (sec): 4.671000000087133e-05\n",
      "[182, 80] loss: 0.004483556078048423, validation loss: 0.004249129382858299, average train time (sec): 4.4932499997685225e-05\n",
      "[182, 120] loss: 0.003985035425284877, validation loss: 0.0042203548144689705, average train time (sec): 4.332249999947635e-05\n",
      "[182, 160] loss: 0.004262752737849951, validation loss: 0.004258942105016619, average train time (sec): 4.8050000000898765e-05\n",
      "[183, 40] loss: 0.00408529814449139, validation loss: 0.004278485751095807, average train time (sec): 4.924749999872802e-05\n",
      "[183, 80] loss: 0.004126115661347285, validation loss: 0.004217004188213427, average train time (sec): 4.4379999999932805e-05\n",
      "[183, 120] loss: 0.004338032769737765, validation loss: 0.0042481616991659945, average train time (sec): 4.723749999868687e-05\n",
      "[183, 160] loss: 0.00424548463197425, validation loss: 0.004250652793759726, average train time (sec): 4.8684999998727105e-05\n",
      "[184, 40] loss: 0.003938327950891107, validation loss: 0.004267972235058276, average train time (sec): 4.6802500000353577e-05\n",
      "[184, 80] loss: 0.004207060241606086, validation loss: 0.004255761115653616, average train time (sec): 4.4132499999705034e-05\n",
      "[184, 120] loss: 0.004706152545986697, validation loss: 0.004244380296682412, average train time (sec): 4.964500000141925e-05\n",
      "[184, 160] loss: 0.004281512269517407, validation loss: 0.004257528098159522, average train time (sec): 4.9319999999397626e-05\n",
      "[185, 40] loss: 0.004328131600050256, validation loss: 0.004224548437017596, average train time (sec): 4.436000000112017e-05\n",
      "[185, 80] loss: 0.004245552152860909, validation loss: 0.0042264643828121, average train time (sec): 4.600750000065546e-05\n",
      "[185, 120] loss: 0.004112435935530812, validation loss: 0.004219137118988723, average train time (sec): 4.661750000138909e-05\n",
      "[185, 160] loss: 0.0038818340573925523, validation loss: 0.004228220321238041, average train time (sec): 4.476750000037555e-05\n",
      "[186, 40] loss: 0.0041248926485422995, validation loss: 0.004235736858802584, average train time (sec): 4.495249999934003e-05\n",
      "[186, 80] loss: 0.003937654179753736, validation loss: 0.004215159014148533, average train time (sec): 4.328499999814994e-05\n",
      "[186, 120] loss: 0.004427452792879194, validation loss: 0.004193193797584412, average train time (sec): 4.780250000067099e-05\n",
      "[186, 160] loss: 0.004088970232987777, validation loss: 0.004223790379979138, average train time (sec): 4.551750000132415e-05\n",
      "[187, 40] loss: 0.004236713779391721, validation loss: 0.004233843923704523, average train time (sec): 4.707500000051823e-05\n",
      "[187, 80] loss: 0.004016916733235121, validation loss: 0.004215690500612529, average train time (sec): 4.8587500000962794e-05\n",
      "[187, 120] loss: 0.004039001581259072, validation loss: 0.0042073661681124065, average train time (sec): 4.6360000001754995e-05\n",
      "[187, 160] loss: 0.004202343494398519, validation loss: 0.004222987123044595, average train time (sec): 5.292750000194246e-05\n",
      "[188, 40] loss: 0.004220287944190204, validation loss: 0.0042208743167443654, average train time (sec): 4.4857500000716755e-05\n",
      "[188, 80] loss: 0.004053525818744674, validation loss: 0.004220990604668294, average train time (sec): 4.528249999964373e-05\n",
      "[188, 120] loss: 0.004255113308317959, validation loss: 0.004205873372244104, average train time (sec): 4.7354999998106e-05\n",
      "[188, 160] loss: 0.004148148943204433, validation loss: 0.004210895261252826, average train time (sec): 4.6852500000227336e-05\n",
      "[189, 40] loss: 0.004072635341435671, validation loss: 0.0042089089215293805, average train time (sec): 5.208499999866945e-05\n",
      "[189, 80] loss: 0.004290760430740193, validation loss: 0.004232911691772488, average train time (sec): 4.543000000012398e-05\n",
      "[189, 120] loss: 0.004051979741780088, validation loss: 0.004232680244933603, average train time (sec): 4.837250000093718e-05\n",
      "[189, 160] loss: 0.004538173408946022, validation loss: 0.004246339377648426, average train time (sec): 4.326499999933731e-05\n",
      "[190, 40] loss: 0.004017343145096675, validation loss: 0.004190544083819918, average train time (sec): 4.599499999926593e-05\n",
      "[190, 80] loss: 0.004160803620470688, validation loss: 0.004198696547767745, average train time (sec): 4.684249999797885e-05\n",
      "[190, 120] loss: 0.004261917027179152, validation loss: 0.00420881826694141, average train time (sec): 4.671000000087133e-05\n",
      "[190, 160] loss: 0.004342450440162793, validation loss: 0.004200990900467589, average train time (sec): 5.130499999950189e-05\n",
      "[191, 40] loss: 0.004001531121321023, validation loss: 0.004269274597425225, average train time (sec): 4.559749999941687e-05\n",
      "[191, 80] loss: 0.004064702725736424, validation loss: 0.004170169623322644, average train time (sec): 4.6567500001515326e-05\n",
      "[191, 120] loss: 0.004370256402762607, validation loss: 0.004196146797423936, average train time (sec): 4.705249999972239e-05\n",
      "[191, 160] loss: 0.004474602406844497, validation loss: 0.0041953702457249165, average train time (sec): 4.539749999992182e-05\n",
      "[192, 40] loss: 0.003908642038004473, validation loss: 0.0042135192889649915, average train time (sec): 5.1067500001522605e-05\n",
      "[192, 80] loss: 0.004220899171195924, validation loss: 0.004194149106108355, average train time (sec): 4.398250000008375e-05\n",
      "[192, 120] loss: 0.004223337984876707, validation loss: 0.004194997589297171, average train time (sec): 4.25499999977319e-05\n",
      "[192, 160] loss: 0.0043731510289944705, validation loss: 0.004132849774938429, average train time (sec): 4.7867500001075314e-05\n",
      "[193, 40] loss: 0.004133088077651337, validation loss: 0.004196631950589846, average train time (sec): 5.4587500000025105e-05\n",
      "[193, 80] loss: 0.004240929160732776, validation loss: 0.004181921442548903, average train time (sec): 4.822500000045693e-05\n",
      "[193, 120] loss: 0.004208476713392884, validation loss: 0.0041933459062832145, average train time (sec): 4.3644999999514765e-05\n",
      "[193, 160] loss: 0.004137647291645408, validation loss: 0.004208026431887498, average train time (sec): 4.352750000009564e-05\n",
      "[194, 40] loss: 0.004394419322488829, validation loss: 0.0042022834751614425, average train time (sec): 4.625750000002427e-05\n",
      "[194, 80] loss: 0.004372624738607556, validation loss: 0.004209725950616148, average train time (sec): 4.6924999998054774e-05\n",
      "[194, 120] loss: 0.0038994368689600377, validation loss: 0.0041886822338093, average train time (sec): 4.28799999980356e-05\n",
      "[194, 160] loss: 0.003938044619280845, validation loss: 0.004257932340480246, average train time (sec): 4.565750000153912e-05\n",
      "[195, 40] loss: 0.003959253092762083, validation loss: 0.004192034946754575, average train time (sec): 5.2395000000160505e-05\n",
      "[195, 80] loss: 0.004018909833393991, validation loss: 0.004208876830437836, average train time (sec): 4.365750000090429e-05\n",
      "[195, 120] loss: 0.004368692939169705, validation loss: 0.004245635754657241, average train time (sec): 4.478500000004715e-05\n",
      "[195, 160] loss: 0.004370447935070842, validation loss: 0.004239369544007306, average train time (sec): 4.2662499998868954e-05\n",
      "[196, 40] loss: 0.004084614233579487, validation loss: 0.004219643400437286, average train time (sec): 4.1182499998626554e-05\n",
      "[196, 80] loss: 0.004161182430107146, validation loss: 0.004243280699054869, average train time (sec): 5.2547500001765005e-05\n",
      "[196, 120] loss: 0.004283756332006306, validation loss: 0.00422497971405117, average train time (sec): 4.7815000002060515e-05\n",
      "[196, 160] loss: 0.004187271377304569, validation loss: 0.004188675024845409, average train time (sec): 4.940999999973883e-05\n",
      "[197, 40] loss: 0.003984398092143238, validation loss: 0.004237573769576145, average train time (sec): 4.668750000007549e-05\n",
      "[197, 80] loss: 0.004197454475797713, validation loss: 0.00420344393384063, average train time (sec): 4.734249999955864e-05\n",
      "[197, 120] loss: 0.004381644556997344, validation loss: 0.004231290839050176, average train time (sec): 4.425749999938944e-05\n",
      "[197, 160] loss: 0.004465330630773678, validation loss: 0.004215137312575331, average train time (sec): 4.848749999837309e-05\n",
      "[198, 40] loss: 0.004240234306780622, validation loss: 0.004193408454258768, average train time (sec): 5.047500000046057e-05\n",
      "[198, 80] loss: 0.004423451697221026, validation loss: 0.004265666249612311, average train time (sec): 4.7587500000645376e-05\n",
      "[198, 120] loss: 0.004068953718524426, validation loss: 0.004190594608069591, average train time (sec): 4.854499999851214e-05\n",
      "[198, 160] loss: 0.0039994366990868, validation loss: 0.0041900374575184205, average train time (sec): 4.942500000026939e-05\n",
      "[199, 40] loss: 0.004465080995578319, validation loss: 0.004166025646417489, average train time (sec): 4.854750000049535e-05\n",
      "[199, 80] loss: 0.00400435485644266, validation loss: 0.004192868445314608, average train time (sec): 5.446499999948173e-05\n",
      "[199, 120] loss: 0.0038125965395011006, validation loss: 0.004177569064645554, average train time (sec): 4.724499999895215e-05\n",
      "[199, 160] loss: 0.004248075949726626, validation loss: 0.00422837437165655, average train time (sec): 5.034499999965192e-05\n",
      "Saved checkpoint for epoch 199: PC_ConvMF_r12_cdim2-c00f\n",
      "Saved checkpoint for epoch 199: PC_ConvMF_r12_cdim2-c00f\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(output_run_dir):\n",
    "    os.mkdir(output_run_dir)\n",
    "\n",
    "# Save details\n",
    "with open(os.path.join(output_run_dir, f\"details_{runname}.json\"), \"w\" ) as write:\n",
    "    json.dump(run_details, write, indent=2 )\n",
    "\n",
    "\n",
    "for model in models:\n",
    "    writer = SummaryWriter(os.path.join(tensorboard_dir, f'{machine}_{model.get_name()}_{runname}'))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    train_model(model=model, \n",
    "                optimizer=optimizer,\n",
    "                train_data=train_dataloader,\n",
    "                validate_data=validation_dataloader,\n",
    "                output_run_dir=output_run_dir,\n",
    "                **run_details[\"run_params\"], \n",
    "                writer=writer, \n",
    "                load=True\n",
    "               )\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b6ee6-a883-49ff-9f5f-24770bda2e8e",
   "metadata": {},
   "source": [
    "### Single model running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df346cd8-400c-4862-a208-c0240bf79bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DANMF\n",
      "[0, 40] loss: 0.9970015108585357, validation loss: 0.9977373278365945, average train time (sec): 8.640750000381559e-05\n",
      "[0, 80] loss: 0.9970015019178391, validation loss: 0.9977372952227322, average train time (sec): 8.593250000217267e-05\n",
      "[0, 120] loss: 0.9960014522075653, validation loss: 0.9977373075935075, average train time (sec): 9.168500000100721e-05\n",
      "[0, 160] loss: 0.9970014408230782, validation loss: 0.9984920373502767, average train time (sec): 8.531999999945583e-05\n",
      "[1, 40] loss: 0.9960015803575516, validation loss: 0.9977373053442757, average train time (sec): 8.184499999970285e-05\n",
      "[1, 80] loss: 0.9970013990998268, validation loss: 0.9977373098427395, average train time (sec): 9.473500000467538e-05\n",
      "[1, 120] loss: 0.9970014497637749, validation loss: 0.9977373030950438, average train time (sec): 8.481999999503387e-05\n",
      "[1, 160] loss: 0.9980013832449913, validation loss: 0.9977372974719642, average train time (sec): 8.727500000986766e-05\n",
      "[2, 40] loss: 0.9970014646649361, validation loss: 0.9977372985965801, average train time (sec): 8.636249999653956e-05\n",
      "[2, 80] loss: 0.9990015625953674, validation loss: 0.9977373165904351, average train time (sec): 8.732500000405708e-05\n",
      "[2, 120] loss: 0.9930014714598656, validation loss: 0.9977373109673554, average train time (sec): 8.708750000323562e-05\n",
      "[2, 160] loss: 0.9980014637112617, validation loss: 0.9977373244627467, average train time (sec): 8.351500000571832e-05\n",
      "[3, 40] loss: 0.9960014000535011, validation loss: 0.9977372985965801, average train time (sec): 8.849250000366737e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_run_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_at\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_pr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# with profiler.profile(activities=[profiler.ProfilerActivity.CPU, profiler.ProfilerActivity.CUDA] if use_cuda else [profiler.ProfilerActivity.CPU],\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#                          record_shapes=False, \u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#                          profile_memory=True, \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#         with profiler.record_function(\"train_model\"):\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#             train_model(15, model, optimizer, checkpoint_at=5, writer=writer, load=False, profiler=prof)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 60\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, optimizer, output_run_dir, epochs, checkpoint_at, load, batch_pr, writer, profiler, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     58\u001b[0m running_time \u001b[38;5;241m=\u001b[39m default_timer() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m---> 60\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Print and save statistics\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m batch_pr \u001b[38;5;241m==\u001b[39m batch_pr \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:    \u001b[38;5;66;03m# print every 200 mini-batches\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # model = Fork(nn_rank, img_size, [500, 200], [200, 300]).to(device)\n",
    "# model = model_danmf\n",
    "# runname = \"Better_opt\"\n",
    "# output_run_dir = output_dir\n",
    "# writer = SummaryWriter(os.path.join(tensorboard_dir, f'{machine}_{model.get_name()}_{runname}'))\n",
    "\n",
    "# # Optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# # optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "# train_model(model, optimizer, output_run_dir, epochs=120, checkpoint_at=30, batch_pr=40, writer=writer, load=False)\n",
    "\n",
    "## Profiling code\n",
    "# with profiler.profile(activities=[profiler.ProfilerActivity.CPU, profiler.ProfilerActivity.CUDA] if use_cuda else [profiler.ProfilerActivity.CPU],\n",
    "#                          record_shapes=False,\n",
    "#                          profile_memory=True,\n",
    "#                          # use_cuda=use_cuda,\n",
    "#                          schedule=torch.profiler.schedule(\n",
    "#                             wait=1,\n",
    "#                             warmup=1,\n",
    "#                             active=2,\n",
    "#                             repeat=1),\n",
    "#                          on_trace_ready=trace_handler\n",
    "#                          ) as prof:\n",
    "#         with profiler.record_function(\"train_model\"):\n",
    "#             train_model(15, model, optimizer, checkpoint_at=5, writer=writer, load=False, profiler=prof)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f4507d-53f1-43b0-94d7-c0b0cdbdfcfd",
   "metadata": {},
   "source": [
    "## Winners\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6211000-7c2a-4c3f-810f-7453d21d7641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
