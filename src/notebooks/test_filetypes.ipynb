{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b536bf86-1a3f-4194-8f6f-cabe90a73f41",
   "metadata": {},
   "source": [
    "# Test speed of loading different filetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcef177b-3bab-428d-8d4f-7b5adcfddf55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T11:10:48.668545Z",
     "iopub.status.busy": "2024-02-16T11:10:48.668245Z",
     "iopub.status.idle": "2024-02-16T11:10:48.672593Z",
     "shell.execute_reply": "2024-02-16T11:10:48.671627Z",
     "shell.execute_reply.started": "2024-02-16T11:10:48.668523Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from timeit import default_timer\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdf655cd-263c-48ea-ba5e-312655b9ae68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T11:18:24.007725Z",
     "iopub.status.busy": "2024-02-16T11:18:24.007381Z",
     "iopub.status.idle": "2024-02-16T11:18:24.469236Z",
     "shell.execute_reply": "2024-02-16T11:18:24.468491Z",
     "shell.execute_reply.started": "2024-02-16T11:18:24.007695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../data/gen_plasma_n64/mat_0', '../../data/gen_plasma_n64/mat_1', '../../data/gen_plasma_n64/mat_2'] [8145, 8145, 5685]\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.normpath(\"../../data\")\n",
    "folders = [os.path.join(data_path, \"gen_plasma_n64\", f\"mat_{i}\") for i in range(3)]\n",
    "lens = [int(len(list(filter(lambda x: x.endswith(\".csv\"), os.listdir(f)))) / 4) for f in folders]\n",
    "\n",
    "print(folders, lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06925f93-d61d-4e39-a10e-f4dbf45cbe7a",
   "metadata": {},
   "source": [
    "## CSV format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f7209-6490-40a7-8791-e573d08d91ff",
   "metadata": {},
   "source": [
    "### Loading one matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "170bd044-da4f-4158-be2a-d6891de67cc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T11:19:39.690026Z",
     "iopub.status.busy": "2024-02-16T11:19:39.689588Z",
     "iopub.status.idle": "2024-02-16T11:33:29.848454Z",
     "shell.execute_reply": "2024-02-16T11:33:29.846759Z",
     "shell.execute_reply.started": "2024-02-16T11:19:39.689985Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m default_timer()\n\u001b[0;32m---> 10\u001b[0m     tstload \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenfromtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m default_timer() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     13\u001b[0m times_csv\u001b[38;5;241m.\u001b[39mappend(time \u001b[38;5;241m/\u001b[39m lens[i])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/numpy/lib/npyio.py:2006\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[1;32m   2003\u001b[0m first_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m first_values:\n\u001b[0;32m-> 2006\u001b[0m     first_line \u001b[38;5;241m=\u001b[39m _decode_line(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfhd\u001b[49m\u001b[43m)\u001b[49m, encoding)\n\u001b[1;32m   2007\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (comments \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2008\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m comments \u001b[38;5;129;01min\u001b[39;00m first_line:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "times_csv = []\n",
    "\n",
    "for i, folder in enumerate(folders):\n",
    "    time = 0\n",
    "\n",
    "    for f in range(lens[i]):\n",
    "        path = os.path.join(folder, f\"f_{f}.csv\")\n",
    "\n",
    "        start_time = default_timer()\n",
    "        tstload = np.genfromtxt(path, delimiter=\",\", dtype=float)\n",
    "        time += default_timer() - start_time\n",
    "\n",
    "    times_csv.append(time / lens[i])\n",
    "    print(times_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a98adb9-d84e-438c-b477-e901e1fd5918",
   "metadata": {},
   "source": [
    "## Convert to HDF5\n",
    "\n",
    "Only run this code once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fbf1f-3028-41b6-807d-745c671be392",
   "metadata": {},
   "source": [
    "### Loading all 4 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27dff1ba-5601-4aea-a02e-c03d554ff5b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T11:33:31.978598Z",
     "iopub.status.busy": "2024-02-16T11:33:31.978233Z",
     "iopub.status.idle": "2024-02-16T11:33:33.328644Z",
     "shell.execute_reply": "2024-02-16T11:33:33.327964Z",
     "shell.execute_reply.started": "2024-02-16T11:33:31.978569Z"
    }
   },
   "outputs": [],
   "source": [
    "# paths = [os.path.join(folders[0], f\"{s}_0.csv\") for s in (\"f\", \"S\", \"U\", \"V\")]\n",
    "\n",
    "# m_f = np.genfromtxt(paths[0], delimiter=\",\", dtype=float)\n",
    "# m_S = np.genfromtxt(paths[1], delimiter=\",\", dtype=float)\n",
    "# m_U = np.genfromtxt(paths[2], delimiter=\",\", dtype=float)\n",
    "# m_V = np.genfromtxt(paths[3], delimiter=\",\", dtype=float)\n",
    "\n",
    "# with h5py.File(os.path.join(folders[0], '0.hdf5'), 'w') as file:\n",
    "#     file.create_dataset(\"f\", data=m_f)\n",
    "#     file.create_dataset(\"S\", data=m_S)\n",
    "#     file.create_dataset(\"U\", data=m_U)\n",
    "#     file.create_dataset(\"V\", data=m_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "300e39f7-7bf9-4d64-b867-a62b9cf1f25e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T11:40:27.240231Z",
     "iopub.status.busy": "2024-02-16T11:40:27.239879Z",
     "iopub.status.idle": "2024-02-16T11:40:27.251243Z",
     "shell.execute_reply": "2024-02-16T11:40:27.250305Z",
     "shell.execute_reply.started": "2024-02-16T11:40:27.240203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 file \"0.hdf5\" (mode r)> <KeysViewHDF5 ['S', 'U', 'V', 'f']>\n",
      "<HDF5 dataset \"f\": shape (64, 128), type \"<f8\">\n",
      "[[2.15367463e-09 3.93651655e-09 7.16342953e-09 ... 7.31011585e-09\n",
      "  4.02170458e-09 2.18977458e-09]\n",
      " [2.12611971e-09 3.87617972e-09 7.05779149e-09 ... 7.34854840e-09\n",
      "  4.04503671e-09 2.19767585e-09]\n",
      " [2.09272750e-09 3.80517765e-09 6.93264068e-09 ... 7.36230817e-09\n",
      "  4.05470692e-09 2.19846995e-09]\n",
      " ...\n",
      " [2.19767584e-09 4.04503670e-09 7.34854840e-09 ... 7.05779149e-09\n",
      "  3.87617972e-09 2.12611972e-09]\n",
      " [2.18977457e-09 4.02170458e-09 7.31011585e-09 ... 7.16342953e-09\n",
      "  3.93651655e-09 2.15367464e-09]\n",
      " [2.17500809e-09 3.98529515e-09 7.24800450e-09 ... 7.24800450e-09\n",
      "  3.98529515e-09 2.17500809e-09]] (64, 128) 8192 float64 <class 'numpy.ndarray'> 0.00265982621971962\n"
     ]
    }
   ],
   "source": [
    "# with h5py.File(os.path.join(folders[0], '0.hdf5'), 'r') as file:\n",
    "#     print(file, file.keys())\n",
    "#     print(file[\"f\"])\n",
    "#     new_f = file[\"f\"][()] # The syntax actually retrtrieves and stores the data\n",
    "\n",
    "# print(new_f, new_f.shape, new_f.size, new_f.dtype, type(new_f), new_f[0, 30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b8a44-5fc0-429b-85ec-2da9118c933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_allm_csv = []\n",
    "\n",
    "for i, folder in enumerate(folders):\n",
    "    time = 0\n",
    "    \n",
    "    for f in range(lens[i]):\n",
    "        paths = [os.path.join(folder, f\"{s}_{f}.csv\") for s in (\u0000 \u0000i\u0000n\u0000 \u0000[\u0000\"\u0000f\u0000\"\u0000,)]\n",
    "\n",
    "        start_time = default_timer()\n",
    "        m_f = np.genfromtxt(paths[0], delimiter=\",\", dtype=float)\n",
    "        m_S = np.genfromtxt(paths[1], delimiter=\",\", dtype=float)\n",
    "        m_U = np.genfromtxt(paths[2], delimiter=\",\", dtype=float)\n",
    "        m_V = np.genfromtxt(paths[3], delimiter=\",\", dtype=float)\n",
    "        time += default_timer() - start_time\n",
    "\n",
    "        with h5py.File(os.path.join(folder, f'{f}.hdf5'), 'w') as file:\n",
    "                file.create_dataset(\"f\", data=m_f)\n",
    "                file.create_dataset(\"S\", data=m_S)\n",
    "                file.create_dataset(\"U\", data=m_U)\n",
    "                file.create_dataset(\"V\", data=m_V)\n",
    "\n",
    "    times_allm_csv.append(time / lens[i])\n",
    "    print(f\"Done {folder}, times: {times_allm_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d212aca-2d23-4bbb-8222-27b9e532804b",
   "metadata": {},
   "source": [
    "## HDF5 Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61797a63-0bb9-4616-9309-eb3b7307af1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "379af421-e56d-4420-8a10-95d8c39a7a19",
   "metadata": {},
   "source": [
    "## MAT Format\n",
    "\n",
    "Assumes that the mats were generated by Matlab; cannot use the original plasma gen code, need to actually load the csvs and save as `.mat`s becuse need to be the exact same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6dc093-39b0-4347-bcef-36bc66efe2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
